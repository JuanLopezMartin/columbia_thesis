[["index.html", "Multilevel Regression and Poststratification Case Studies Chapter 1 Notes", " Multilevel Regression and Poststratification Case Studies Juan Lopez-Martin, Justin H. Phillips, and Andrew Gelman1 2020-12-17 Chapter 1 Notes The following case studies intend to introduce users to Multilevel Modeling and Poststratification (MRP) and some of its extensions, providing reusable code and clear explanations. The first chapter presents MRP, a statistical technique that allows to estimate subnational estimates from national surveys while adjusting for nonrepresentativeness. The second chapter extends MRP to overcome the limitation of only using variables included in the census. The last chapter develops a new approach that combines MRP within an ideal point model, allowing to obtain subnational estimates of latent attitudes based on multiple survey questions and improving the subnational estimates for an individual survey item based on other related items. The tutorials assume certain familiarity with R and Bayesian Statistics. A good reference to the required background is Gelman, Hill, and Vehtari (2020). Additionally, multilevel models are covered in Gelman and Hill (2006) (Part 2A) or McElreath (2020) (Chapters 12 and 13). The case studies are still under development. Please send any feedback to jl5522@columbia.edu. References "],["introduction-to-mrp.html", "Chapter 2 Introduction to MRP 2.1 The Data 2.2 First stage: Estimating the Individual-Response Model 2.3 Second Stage: Poststratification 2.4 Adjusting for Nonrepresentative Surveys 2.5 Practical Considerations 2.6 Appendix: Data Preprocessing for CCES and Census Data", " Chapter 2 Introduction to MRP h1.title { font-size: 32px; text-align: center; } h2 { padding-bottom: 4px; } h4.author { padding-top: 22px; text-align: center; font-style: italic; } h4.date { padding-top: 14px; font-size: 14px; text-align: center; font-style: italic; padding-bottom: 20px; } #myDIV { width: 100%; padding: 20px 30px; background-color: rgba(192,192,192,0.15); margin-top: 10px; border-radius: 4px; } #myButton{ border-color: #008CBA; background-color: rgba(192,192,192,0.05); color: #008CBA; border-radius: 4px; } #myDIV2 { width: 100%; padding: 20px 30px; background-color: rgba(192,192,192,0.15); margin-top: 10px; border-radius: 4px; } #myButton2{ border-color: #008CBA; background-color: rgba(192,192,192,0.05); color: #008CBA; border-radius: 4px; } #myDIV3 { width: 100%; padding: 20px 30px; background-color: rgba(192,192,192,0.15); margin-top: 10px; border-radius: 4px; } #myButton3{ border-color: #008CBA; background-color: rgba(192,192,192,0.05); color: #008CBA; border-radius: 4px; } Multilevel Modeling and Poststratification (MRP) has become widely used in two closely related applications: Small-area estimation: Sub-national surveys are not always available, and even then finding comparable surveys across sub-national units is rare. However, public views at the sub-national level are often central, as many policies are decided by local goverments or sub-national area representatives at national assemblies. MRP allows us to use national surveys to generate reliable estimates of sub-national opinion (Park, Gelman, and Bafumi (2004), Lax and Phillips (2009a), Lax and Phillips (2009b), Kiewiet de Jonge, Langer, and Sinozich (2018)). Using nonrepresentative surveys: Many surveys face serious difficulties in recruiting representative samples of participants (e.g. because of non-response bias). However, with proper statistical adjustment, nonrepresentative surveys can be used to generate accurate opinion estimates (Wang et al. (2015), Downes et al. (2018)). In this case study, we will show how to use MRP to estimate public opinion. In the first section we introduce the data. Then, we describe the two essential stages of MRP: building an individual-response model and using poststratification. That is, first, we take individual responses to national surveys and use multilevel modeling in order to predict opinion estimates based on demographic-geographic subgroups (e.g. middle-aged white female with postgraduate education in California). Secondly, these opinion estimates by subgroups are weighted by the frequency of these subgroups at the (national or subnational) unit of interest. In the fourth section we show how MRP can be used to obtain accurate national estimates from a biased sample. Lastly, the five section introduces some practical considerations. All the code is also available in the Rmarkdown file on GitHub. 2.1 The Data 2.1.1 Survey data The first step is to gather and recode raw survey data. These surveys should include some respondent demographic information and some type of geographic indicator (e.g. state, congressional district). In this case, we will use data from the 2018 Cooperative Congressional Election Study (CCES), a US nationwide survey designed by a consortium of 60 research teams and administered by YouGov. The outcome of interest in this introduction is a dichotomous question: Allow employers to decline coverage of abortions in insurance plans (Support / Oppose) Apart from the outcome measure, we will consider a set of factors that will be used as predictors in the first stage and that will be used to define the geographic-demographic subgroups for the second stage. Even though some of these variables may be continous (e.g. age, income), we must make sure to split them into intervals to create a factor with different levels. Importantly, and as we will see in a moment, these factors and their corresponding levels need to match the ones in the postratification table. In this case, we will use the following demographic-geographic factors with the indicated levels: State: 50 US states (\\(S = 50\\)). Age: 18-29, 30-39, 40-49, 50-59, 60-69, 70+ (\\(A = 6\\)). Gender: Female, Male (\\(G = 2\\)). Ethnicity: (Non-hispanic) White, Black, Hispanic, Other (which also includes Mixed) (\\(R = 4\\)). Education: No HS, HS, Some college, 4-year college, Post-grad (\\(E = 5\\)). df_all &lt;- read.csv(&quot;cces18_common_vv.csv&quot;) # Vector containing the abbreviated names for the 50 states under consideration list_states_abb &lt;- datasets::state.abb # FIPS code for the 50 states. The CCES data uses FIPS codes to identify states, # and therefore we need these to read the data and transform the FIPS codes # to abbreviated names list_states_num &lt;- c(1,2,4,5,6,8,9,10,12,13,15,16,17,18,19,20,21,22,23,24, 25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42, 44,45,46,47,48,49,50,51,53,54,55,56) # Preprocessing df_all &lt;- clean_cces(df_all, list_states_abb, list_states_num) # Population and states estimates for all the respondents pop_estimate_all &lt;- mean(df_all$abortion) state_estimates_all &lt;- df_all %&gt;% group_by(state) %&gt;% summarise(estimate = mean(abortion)) state_n_all &lt;- df_all %&gt;% group_by(state) %&gt;% summarise(N_all = n()) Details about how we preprocess the CCES data using the clean_cces() function can be found in the appendix. The full 2018 CCES consist of almost 60,000 respondents. However, most studies work with a smaller national survey. To show how MRP works in these cases, we will take a random sample of 5,000 participants of the CCES and work with the sample instead of the full CCES. Obviously, in a more realistic setting we would always use all the data that we have available. # For clarity, we will call the full survey with 60,000 respondents df_all, # while the 5,000 person sample will be called df (which stands for data frame). set.seed(1010) # We set the seed to an arbitrary number for reproducibility. df &lt;- df_all %&gt;% sample_n(5000) knitr::kable(head(df), format = &#39;markdown&#39;) abortion state eth male age educ 1 WI White -0.5 60-69 4-Year College 1 NJ White -0.5 60-69 HS 0 FL White -0.5 40-49 HS 1 FL White 0.5 70+ Some college 0 IL White -0.5 50-59 Some college 0 OK Other -0.5 18-29 Some college 2.1.2 Poststratification table The poststratification table reflects the number of people in the population of interest that, according to a large survey, corresponds to each combination of the demographic-geographic factors. In the US context it is typical to use Decennial Census data or the American Community Survey, although we can of course use any other large-scale surveys that reflects the frequency of the different demographic types within any geographic variables of interest. The poststratification table will be used in the second stage to poststratify the estimates obtained for each subgroup. For this, it is central that the factors (and their levels) used in the survey match the factors obtained in the census. Therefore, MRP is in principle limited to use individual-level variables that are present both the survey and the census, although in the next chapter we will relax this requirement. For instance, the CCES includes information on respondents religion, but as this information is not available in the census we are not able to use this variable. Similarly, the levels of the factors in the census are required to match the ones in the census. For instance, in our case the CCES included Middle Eastern as an option for ethnicity, while the large-scale survey we used did not include it. Therefore, people who identified as Middle Eastern in the CCES need to be included in the Other category. In this case, we will base our poststratification table in the 2014-2018 American Community Survey (ACS), a set of yearly surveys conducted by the US Census that provides estimates of the number of US residents according to a series of variables that include our poststratification variables. As we defined the levels for these variables, the poststratification table must have \\(50 \\times 6 \\times 2 \\times 4 \\times 5 = 12,000\\) rows. This means we actually have more rows in the poststratification table than observed units, which necessarily implies that there are some combinations in the poststratification table that we dont observe in the CCES sample. # Load data frame created in the appendix. The data frame that contains the poststratification # table is called postrat_df postrat_df &lt;- read.csv(&quot;postrat_data.csv&quot;) postrat_df$state &lt;- factor(postrat_df$state, levels = list_states_num, labels = list_states_abb) knitr::kable(head(postrat_df), format = &#39;markdown&#39;) X state eth male age educ n 1 AL White -0.5 18-29 No HS 23948 2 AL White -0.5 18-29 HS 59378 3 AL White -0.5 18-29 Some college 104855 4 AL White -0.5 18-29 4-Year College 37066 5 AL White -0.5 18-29 Post-grad 9378 6 AL White -0.5 30-39 No HS 14303 For instance, the first row in the poststratification table indicates that there are 23,948 Alabamians that are white, male, between 18 and 29 years old, and without a high school degree. Every MRP study requires some degree of data wrangling in order to make the factors in the survey of interest match the factors available in the census. The code shown in the Appendix can be used as a template to download the ACS data and make it match with a given survey of interest. 2.1.3 Group-level predictors The individual-response model used in the first stage can include group-level predictors, which tend to reduce unexplained group level variation by accounting for structured differences among the states. For instance, most national-level surveys in the US tend to include many participants from a state such as New York, but few from a small state like Vermont. This can result in noisy estimates for the effect of being from Vermont. The intuition is that by including state-level predictors, such as the Republican voteshare in a previous election or the percentage of Evangelicals at each state, the model is able to account for how similar is Vermont is to New York and other populous states, and therefore to produce more precise estimates. These group-level predictors do not need to be available in the census nor they have to be converted to factors, and in many cases are readily available. A more detailed discussion on the importance of builidng a reasonable model for predicting opinion, and how state-level predictors can be a key element in this regard, can be found in Lax and Phillips (2009b) and Buttice and Highton (2013). In our example, we will include two state-level predictors: the geographical region (Northeast, North Central, South, and West) and the Republican vote share in the 2016 presidential election. # Read statelevel_predictors.csv in a dataframe called statelevel_predictors statelevel_predictors &lt;- read.csv(&#39;statelevel_predictors.csv&#39;) # Clean factor levels statelevel_predictors$state &lt;- factor(statelevel_predictors$state, levels = list_states_abb, labels = list_states_abb) 2.1.4 Exploratory data analysis In the previous steps we have obtained a 5,000-person sample from the CCES survey and also generated a poststratification table using census data. As a first exploratory step, we will check if the frequencies for the different levels for the factors considered in the CCES data are similar to the frequencies reported in the census. If this was not the case, we will start suspecting some degree of nonresponse bias in the CCES survey. For clarity, the levels in the plots follow their natural order in the case of age and education, ordering the others by the approximate proportion of Republican support. We see that our 5,000-participant CCES sample does not differ too much from the target population according to the American Community Survey. This should not be surprising, as the CCES intends to use a representative sample. In general, we recommend checking the differences between the sample and the target population. In this case, the comparison has been based on the factors that are going to be used in MRP. However, even if some non-response bias existed for any of these factors MRP would be able to adjust for it, as we will see more in detail in subsection 4. Therefore, it may be especially important to compare the sample and target population with respect to the variables that are not going to be used in MRP  and, consequently, where we will not be able to correct any outcome measure bias due to differential non-response in these non-MRP variables. 2.2 First stage: Estimating the Individual-Response Model The first stage is to use a multilevel logistic regression model to predict the outcome measure given the different factors we are considering. Having a plausible model to predict opinion is central for MRP to work well. The model we use in this example is described below. It includes varying intercepts for age, ethnicity, and state, where the variation for the state intercepts is in turn influenced by the region effects (coded as indicator variables) and the Republican vote share in the 2016 election. As there are only two levels for gender, it is preferable to model it as a predictor for computational efficiency. Additionally, we include varying intercepts for the interaction between male and ethnicity, education and age, and education and ethnicity (see Ghitza and Gelman (2013) for an in-depth discussion on the advantages of including interactions). \\[ Pr(y_i = 1) = logit^{-1}( \\alpha_{\\rm s[i]}^{\\rm state} + \\alpha_{\\rm a[i]}^{\\rm age} + \\alpha_{\\rm r[i]}^{\\rm eth} + \\alpha_{\\rm e[i]}^{\\rm educ} + \\beta^{\\rm male} \\cdot {\\rm Male}_{\\rm i} + \\alpha_{\\rm g[i], r[i]}^{\\rm male.eth} + \\alpha_{\\rm e[i], a[i]}^{\\rm educ.age} + \\alpha_{\\rm e[i], r[i]}^{\\rm educ.eth} ) \\] where: \\[ \\begin{align*} \\alpha_{\\rm s}^{\\rm state} &amp;\\sim {\\rm Normal}(\\gamma^0 + \\gamma^{\\rm south} \\cdot {\\rm South}_{\\rm s} + \\gamma^{\\rm northcentral} \\cdot {\\rm NorthCentral}_{\\rm s} + \\gamma^{\\rm west} \\cdot {\\rm West}_{\\rm s} + \\gamma^{\\rm repvote} \\cdot {\\rm RepVote}_{\\rm s}, \\sigma^{\\rm state}) \\textrm{ for s = 1,...,50}\\\\ \\alpha_{\\rm a}^{\\rm age} &amp; \\sim {\\rm Normal}(0,\\sigma^{\\rm age}) \\textrm{ for a = 1,...,6}\\\\ \\alpha_{\\rm r}^{\\rm eth} &amp; \\sim {\\rm Normal}(0,\\sigma^{\\rm eth}) \\textrm{ for r = 1,...,4}\\\\ \\alpha_{\\rm e}^{\\rm educ} &amp; \\sim {\\rm Normal}(0,\\sigma^{\\rm educ}) \\textrm{ for e = 1,...,5}\\\\ \\alpha_{\\rm g,r}^{\\rm male.eth} &amp; \\sim {\\rm Normal}(0,\\sigma^{\\rm male.eth}) \\textrm{ for g = 1,2 and r = 1,...,4}\\\\ \\alpha_{\\rm e,a}^{\\rm educ.age} &amp; \\sim {\\rm Normal}(0,\\sigma^{\\rm educ.age}) \\textrm{ for e = 1,...,5 and a = 1,...,6}\\\\ \\alpha_{\\rm e,r}^{\\rm educ.eth} &amp; \\sim {\\rm Normal}(0,\\sigma^{\\rm educ.eth}) \\textrm{ for e = 1,...,5 and r = 1,...,4}\\\\ \\end{align*} \\] Show model explanation People without a background in multilevel modeling may be surprised to see this formulation. Why are we using terms such as \\(\\alpha_{\\rm eth}^{\\rm eth}\\) instead of the much more common method of creating an indicator variable for each state (e.g. \\(\\beta^{\\rm white} \\cdot {\\rm White}_{i} + \\beta^{\\rm black} \\cdot {\\rm Black}_{i} + ...\\))? The answer is that this approach allows to share information between the levels of each variable (e.g. different ethnicities), preventing levels with less data from being too sensitive to the few observed values. For instance, it could happen that we only surveyed ten Hispanics, and that none of them turned out to agree that employers should be able to decline abortion coverage in insurance plans. Under the typical approach, the model would take this data too seriously and consider that Hispanics necessarily oppose this statement (i.e. \\(\\beta^{\\rm hispanic} = - \\infty\\)). We know, however, that this is not the case. It may be that Hispanics are less likely to support the statement, but from such a small sample size it is impossible to know. What the multilevel model will do is to partially pool the varying intercept for Hispanics towards the average accross all ethnicities (i.e. in our model, the average across all ethnicities is fixed at zero), making it negative but far from the unrealistic negative infinity. This pooling will be data-dependent, meaning that it will pool the varying intercept towards the average more strongly the smaller the sample size in that level. In fact, if the sample size for a certain level is zero, the estimate varying intercept would be the average coefficient for all the other levels. \\(\\alpha_{\\rm a}^{\\rm age}\\): The effect of subject \\(i\\)s age on the probability of supporting the statement. \\(\\alpha_{\\rm r}^{\\rm eth}\\): The effect of subject \\(i\\)s ethnicity on the probability of supporting the statement. \\(\\alpha_{\\rm e}^{\\rm educ}\\): The effect of subject \\(i\\)s education on the probability of supporting the statement. \\(\\alpha_{\\rm s}^{\\rm state}\\): The effect of subject \\(i\\)s state on the probability of supporting the statement. As we have a state-level predictor (the Republican vote share in the 2016 election), we need to build another model in which \\(\\alpha_{\\rm s}^{\\rm state}\\) is the outcome of a linear regression with an expected value determined by an intercept \\(\\gamma^0\\), the effect of the region coded as indicator variables (with Northeast as the baseline level), and the effect of the Republican vote share \\(\\gamma^{\\rm demvote}\\). \\(\\beta^{\\rm male}\\): The average effect of being male on the probability of supporting abortion. We could have used a similar formulation as in the previous cases (i.e. \\(\\alpha_{\\rm g}^{\\rm gender} \\sim N(0, \\sigma^{\\rm gender})\\)), but having only two levels (i.e. male and female) can create some estimation problems. \\(\\alpha_{\\rm e,r}^{\\rm male.eth}\\) and \\(\\alpha_{\\rm e,r}^{\\rm educ.age}\\): In the survey literature it is common practice to include these two interactions. \\(\\alpha_{\\rm e,r}^{\\rm educ.eth}\\): In the next section we will explore public opinion on required abortion coverage at the different levels of education and ethnicity. It is, therefore, a good idea to also include this interaction. See Gelman and Hill (2007) for an introduction to multilevel modeling. The rstanarm package allows the user to conduct complicated regression analyses in Stan with the simplicity of standard formula notation in R. stan_glmer(), the function that allows to fit generalized linear multilevel models, uses the same notation as the lme4 package (see documentation here). That is, we specify the varying intercepts as (1 | group) and the interactions are expressed as (1 | group1:group2), where the : operator creates a new grouping factor that consists of the combined levels of the two groups (i.e. this is the same as pasting together the levels of both factors). However, this syntax only accepts predictors at the individual level, and thus the two state-level predictors must be expanded to the individual level (see [p. 265-266]Gelman and Hill (2007)). Notice that: \\[ \\begin{align*} \\alpha_{\\rm s}^{\\rm state} &amp;\\sim {\\rm Normal}(\\gamma^0 + \\gamma^{\\rm south} \\cdot {\\rm South}_{\\rm s} + \\gamma^{\\rm northcentral} \\cdot {\\rm NorthCentral}_{\\rm s} + \\gamma^{\\rm west} \\cdot {\\rm West}_{\\rm s} + \\gamma^{\\rm repvote} \\cdot {\\rm RepVote}_{\\rm s}, \\sigma^{\\rm state}) \\\\ &amp;= \\underbrace{\\gamma^0}_\\text{Intercept} + \\underbrace{{\\rm Normal}(0, \\sigma^{\\rm state})}_\\text{State varying intercept} + \\underbrace{\\gamma^{\\rm south} \\cdot {\\rm South}_{\\rm s} + \\gamma^{\\rm northcentral} \\cdot {\\rm NorthCentral}_{\\rm s} + \\gamma^{\\rm west} \\cdot {\\rm West}_{\\rm s} + \\gamma^{\\rm repvote} \\cdot {\\rm RepVote}_{\\rm s}}_\\text{State-level predictors expanded to the individual level} \\end{align*} \\] Consequently, we can then reexpress the model as: \\[ Pr(y_i = 1) = logit^{-1}( \\gamma^0 + \\alpha_{\\rm s[i]}^{\\rm state} + \\alpha_{\\rm a[i]}^{\\rm age} + \\alpha_{\\rm r[i]}^{\\rm eth} + \\alpha_{\\rm e[i]}^{\\rm educ} + \\beta^{\\rm male} \\cdot {\\rm Male}_{\\rm i} + \\alpha_{\\rm g[i], r[i]}^{\\rm male.eth} + \\alpha_{\\rm e[i], a[i]}^{\\rm educ.age} + \\alpha_{\\rm e[i], r[i]}^{\\rm educ.eth} + \\gamma^{\\rm south} \\cdot {\\rm South}_{\\rm s} \\\\ + \\gamma^{\\rm northcentral} \\cdot {\\rm NorthCentral}_{\\rm s} + \\gamma^{\\rm west} \\cdot {\\rm West}_{\\rm s} + \\gamma^{\\rm repvote} \\cdot {\\rm RepVote}_{\\rm s}) \\] In the previous version of the model, \\(\\alpha_{\\rm s[i]}^{\\rm state}\\) was informed by several state-level predictors. This reparametrization expands the state-level predictors at the individual level, and thus \\(\\alpha_{\\rm s[i]}^{\\rm state}\\) now represents the variance introduced by the state adjusting for the region and 2016 Republican vote share. Similarly, \\(\\gamma^0\\), which previously represented the state-level intercept, now becomes the individual-level intercept. The two parameterizations of the multilevel model are mathematically equivalent, and using one or the other is simply a matter of preference. The former one highlights the role that state-level predictos have in accounting for structured differences among the states, while the later is closer to the rstanarm syntax. # Expand state-level predictors to the individual level # df &lt;- left_join(df, statelevel_predictors, by = &quot;state&quot;, keep = TRUE) # # Fit in stan_glmer # fit &lt;- stan_glmer(abortion ~ (1 | state) + (1 | eth) + (1 | educ) + male + # (1 | male:eth) + (1 | educ:age) + (1 | educ:eth) + # repvote + factor(region), # family = binomial(link = &quot;logit&quot;), # data = df, # prior = normal(0, 1, autoscale = TRUE), # prior_covariance = decov(scale = 0.50), # adapt_delta = 0.99, # refresh = 0, # seed = 1010) # # saveRDS(fit, file = &quot;fit_mrp_1.rds&quot;) fit &lt;- readRDS(&quot;fit_mrp_1.rds&quot;) As a first pass to check whether the model is performing well, we must check that there are no warnings about divergences, failure to converge or tree depth. Fitting the model with the default settings produced a few divergent transitions, and thus we decided to try increasing adapt_delta to 0.99 and introducing stronger priors than the rstanarm defaults. After doing this, the divergences dissapeared. In the Computational Issues subsection of this case study we provide more details about divergent transitions and potential solutions. print(fit) ## stan_glmer ## family: binomial [logit] ## formula: abortion ~ (1 | state) + (1 | eth) + (1 | educ) + male + (1 | ## male:eth) + (1 | educ:age) + (1 | educ:eth) + repvote + factor(region) ## observations: 5000 ## ------ ## Median MAD_SD ## (Intercept) -1.2 0.4 ## male 0.4 0.1 ## repvote 1.6 0.5 ## factor(region)Northeast -0.1 0.2 ## factor(region)South 0.2 0.1 ## factor(region)West -0.1 0.1 ## ## Error terms: ## Groups Name Std.Dev. ## state (Intercept) 0.202 ## educ:age (Intercept) 0.200 ## educ:eth (Intercept) 0.083 ## male:eth (Intercept) 0.229 ## educ (Intercept) 0.216 ## eth (Intercept) 0.386 ## Num. levels: state 50, educ:age 30, educ:eth 20, male:eth 8, educ 5, eth 4 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg Show model interpretation Intercept (\\(\\gamma^0\\)): The global intercept corresponds to the expected outcome in the logit scale when having all the predictors equal to zero. In this case, this does not have a clear interpretation, as it is then influenced by the varying intercepts for state, age, ethnicity, education, and interactions. Furthermore, it corresponds to the impractical scenario of someone in a state with zero Republican vote share. male (\\(\\beta^{\\rm male}\\)): The median estimate for this coefficient is 0.4, with a standard error (measured using the Mean Absolute Deviation) of 0.1. Using the divide-by-four rule (Gelman, Hill, and Vehtari (2020), Chapter 13), we see that, adjusting for the other covariates, males present up to a \\(10\\% \\pm 2.5\\%\\) higher probability of supporting the right of employers to decline coverage of abortions relative to females. repvote (\\(\\gamma^{\\rm repvote}\\)): As the scale of repvote was between 0 and 1, this coefficient corresponds to the difference in probability of supporting the statement between someone that was in a state in which no one voted Republican to someone whose state voted all Republican. This is not reasonable, and therefore we start by dividing the median coefficient by 10. Doing this, we consider a difference of a 10% increase in Republican vote share. This means that we expect that someone from a state with a 55% Republican vote share has approximately \\(\\frac{1.5}{10}/4 = 4\\%\\) (\\(\\pm 1\\%\\)) higher probability of supporting the statement relative to another individual with similar characteristics from a state in which Republicans received 45% of the vote. regionSouth (\\(\\gamma^{\\rm south}\\)): According to the model, we expect that someone from a state in the south has, adjusting for the other covariates, up to a 0.1/4 = 2.5% (\\(\\pm 2.5\\%\\)) higher probability of supporting the statement relative to someone from the Northeast, which was the baseline category. The interpretation for regionNorthCentral and regionWest is similar. Error terms (\\(\\sigma^{\\rm state}\\), \\(\\sigma^{\\rm age}\\), \\(\\sigma^{\\rm eth}\\), \\(\\sigma^{\\rm educ}\\), \\(\\sigma^{\\rm male.eth}\\), \\(\\sigma^{\\rm educ.age}\\), \\(\\sigma^{\\rm educ.eth}\\)): Remember that the intercepts for the different levels of state, age, ethnicity, education, and the specified interactions are distributed following a normal distribution centered at zero and with a standard deviation that is estimated from the data. The Error terms section gives us the estimates for these group-level standard deviations. For instance, \\(\\alpha_{\\rm r}^{\\rm ethnicity} \\sim {\\rm Normal}(0, \\sigma^{\\rm ethnicity})\\), where the median estimate for \\(\\sigma^{\\rm ethnicity}\\) is 0.43. In other words, the variyng intercepts for the different ethnicity groups have a standard deviation that is estimated to be 0.43 on the logit scale, or 0.43/4 = 0.11 on the probability scale. In some cases, we may also want to check the intercepts corresponding to the individual levels of a factor. In rstanarm, this can be done using fit$coefficients. For instance, the median values for the varying intercepts of race are \\(\\alpha^{\\rm eth}_{r = {\\rm White}}\\) = 0.14, \\(\\alpha^{\\rm eth}_{r = {\\rm Black}}\\) = -0.28, \\(\\alpha^{\\rm eth}_{r = {\\rm Hispanic}}\\) = 0.04, \\(\\alpha^{\\rm eth}_{r = {\\rm Other}}\\) = 0.08. 2.3 Second Stage: Poststratification 2.3.1 Estimation at the national level Currently, all we have achieved is a model that predicts support on the option for declining abortion coverage given a number of factor-type predictors. To go from this model to a national or sub-national estimate, we need to weight the model predictions for the different subgroups by the actual frequency of these subgroups. This idea can be expressed as: \\[ \\theta^{MRP} = \\frac{\\sum N_{\\rm subgroup} \\theta_{\\rm subgroup}}{\\sum N_{\\rm subgroup}} \\] where \\(\\theta^{MRP}\\) is the MRP estimate, \\(\\theta_{\\rm subgroup}\\) corresponds to the model estimate for a specific subgroup (e.g. young Hispanic men with a High School diploma in Arkansas), and \\(N_{\\rm subgroup}\\) corresponds to the number of people in that subgroup according to the ACS. For a more in-depth review of poststratification, see Chapter 13 of Gelman, Hill, and Vehtari (2020). The values of \\(\\theta_{subgroup}\\) for the different subgroups can be obtained with the posterior_epred() function. Of course, as stan_glmer() performs Bayesian inference, \\(\\theta_{subgroup}\\) for any given subgroup will not be a single point estimate but a vector of posterior draws. # Expand state level predictors to the individual level postrat_df &lt;- left_join(postrat_df, statelevel_predictors, by = &quot;state&quot;, keep = TRUE) # posterior_epred returns the posterior estimates for the different subgroups stored in the postrat_df # dataframe. P &lt;- posterior_epred(fit, newdata = postrat_df, draws = 1000) mrp_estimates &lt;- P %*% postrat_df$n / sum(postrat_df$n) model_popn_pref &lt;- c(mean = mean(mrp_estimates), sd = sd(mrp_estimates)) print(round(model_popn_pref, 2)) ## mean sd ## 0.43 0.01 Show code explanation posterior_epred() returns a matrix \\(P\\) with \\(D\\) rows and \\(J\\) columns, where \\(D\\) corresponds to the number of draws from the posterior distribution (in this case 1000, as we specified draws = 1000) and \\(J\\) is the number of subgroups in the poststratification table (i.e. 12,000). This matrix is multiplied by a vector \\(k\\) of length \\(J\\) that contains the number of people in each subgroup of the poststratification table. This results in a vector of length \\(D\\) that is then divided by the total number of people considered in the poststratification table, a scalar which is calculated by adding all the values in \\(k\\). \\[\\theta^{MRP} = \\frac{P \\times k}{\\sum_j^J k_j}\\] The end result is a vector that we call \\(\\theta^{MRP}\\), and which contains \\(D\\) estimates for the national-level statement support. We can compare these results to the 5,000-person unadjusted sample estimate: sample_popn_pref &lt;- c(mean = mean(df$abortion), se = sqrt(mean(df$abortion)*(1-mean(df$abortion))/nrow(df))) print(round(sample_popn_pref, 2)) ## mean se ## 0.43 0.01 Additionally, we can compare with the population support estimated by the full survey that included the almost 60,000 participants: all_popn_pref &lt;- c(mean = mean(df_all$abortion), se = sqrt(mean(df_all$abortion)*(1-mean(df_all$abortion))/nrow(df_all))) round(all_popn_pref, 2) ## mean se ## 0.43 0.00 In general, we see that both the unadjusted sample estimate and the MRP estimate are quite close to the results of the full survey. In other words, MRP is not providing a notable advantage against the unadjusted sample national estimates. However, it is important to clarify that we were somewhat lucky in obtaining this result as a product of using data from the CCES, a high quality survey that intends to be representative (and appears to be, at least with respect to the variables considered in our poststratification table). Many real-world surveys are not as representative relative to the variables considered in the poststratification step, and in these cases MRP will help correcting the biased estimates from the unadjusted survey. We will see an example of this in section 4, where we exemplify how MRP adjusts a clearly biased sample. 2.3.2 Estimation for sub-national units As we mentioned, small area estimation is one of the main applications of MRP. In this case, we will get an estimate of the support for employers right to decline coverage of abortions per state: \\[ y_{\\rm state}^{MRP} = \\frac{\\sum_{\\rm subgroup \\in state} N_{\\rm subgroup} \\theta_{\\rm subgroup}}{\\sum_{\\rm subgroup \\in state} N_{\\rm subgroup}} \\] # Create empty dataframe state_df &lt;- data.frame( state_num = list_states_num, state = list_states_abb, model_state_pref = rep(NA, length(list_states_num)), model_state_sd = rep(NA, length(list_states_num)), sample_state_pref = rep(NA, length(list_states_num)), all_state_pref = rep(NA, length(list_states_num)), N = rep(NA, length(list_states_num)), N_all = rep(NA, length(list_states_num)) ) state_estimates_all$statename &lt;- list_states_abb # Loop to populate the dataframe for(i in 1:length(levels(postrat_df$state))) { # Currently, the matrix P and the poststratification table contain 12,000 # rows. We need to filter the ones that correspond to state i for each # iteration of the loop. We do so defining the following condition: filtering_condition &lt;- which(postrat_df$state == state_df$state[i]) # Filtering matrix P with filtering_condition P_filtered &lt;- P[ ,filtering_condition] # Filtering poststratification table with filtering_condition k_filtered &lt;- postrat_df[filtering_condition, ]$n # Poststratification step poststrat_prob_state &lt;- P_filtered %*% k_filtered / sum(k_filtered) # This is the MRP estimate for the state state_df$model_state_pref[i] &lt;- mean(poststrat_prob_state) state_df$model_state_sd[i] &lt;- sd(poststrat_prob_state) # This is the 5,000 sample survey estimate for the state, this time filtering df state_df$sample_state_pref[i] &lt;- mean(df$abortion[df$state == list_states_abb[i]]) # This is the 60000-person survey estimate for the state state_df$all_state_pref[i] &lt;- state_estimates_all$estimate[state_estimates_all$statename == list_states_abb[i]] # Sample size in state i for the 5,000 sample survey state_df$N[i] &lt;- nrow(df[df$state == list_states_abb[i], ]) # Sample size in state i for the full 60,000 survey state_df$N_all[i] &lt;- state_n_all$N_all[state_n_all$state==list_states_abb[i]] } state_df$state &lt;- fct_reorder(state_df$state, states_order) We start visualizing the estimates by state from the unadjusted 5,000-person sample. Again, the states are ordered by Republican vote in the 2016 election, and therefore we expect that statement support will follow an increasing trend. In states with small samples, we see considerably wide 95% confidence intervals. We can add the MRP-adjusted estimates to this plot. In general, MRP produces less extreme values by partially pooling information across the factor levels. To illustrate this, we can compare the sample and MRP estimates with the results form the full 60,000-respondent CCES. Of course, in any applied situation we would be using the full survey, but as we took a 5,000 person sample the full 60,000-respondent survey serves as a reference point. Overall, the MRP estimates are closer to the full survey estimates. This is particularly clear for the states with a smaller sample size. As a final way of presenting the MRP estimates, we can plot them on a US map. The symmetric color range goes from 10% to 90% support, as this scale allows for comparison with the other maps. However, the MRP estimates for statement support are concentrated in a relatively small range, which makes the colors appear muted. 2.3.3 Estimation for subgroups within sub-national units MRP can also be used to obtain estimates for more complex cases, such as subgroups within states. For instance, we can study support for declining coverage of abortions by state and ethnicity within state. For clarity, we order the races according to their support for the statement. Similarly, we can look at the outcome in ethnicity-education subgroups by state. 2.4 Adjusting for Nonrepresentative Surveys We have already introduced that MRP is an effective statistical adjustment method to correct for differences between the sample and target population for a set of key variables. We start this second example by obtaining an artificially nonrepresentative sample that gives more weight to respondents that are older, male, and from Republican states. set.seed(1010) # We add the state-level predictors to df_all df_all &lt;- left_join(df_all, statelevel_predictors, by = &quot;state&quot;, keep = TRUE) # We take a sample from df_all giving extra weight to respondents that re older, male, and from Republican states. df &lt;- df_all %&gt;% sample_n(5000, weight = I(5*repvote + (age==&quot;18-29&quot;)*0.5 + (age==&quot;30-39&quot;)*1 + (age==&quot;40-49&quot;)*2 + (age==&quot;50-59&quot;)*4 + (age==&quot;60-69&quot;)*6 + (age==&quot;70+&quot;)*8 + (male==1)*20 + (eth==&quot;White&quot;)*1.05)) df$state &lt;- factor(df$state, levels = list_states_abb, labels = list_states_abb) As expected, our remarkably nonrepresentative sample produces estimates that are lower than what we obtained by using a random sample in the previous section. MRP seems to partially correct for the nonrepresentative sample: Lastly, we see how the MRP national and sub-national estimates based on the nonrepresentative sample are, overall, much closer to the 60,000-person survey than the biased unadjusted sample estimates. 2.5 Practical Considerations 2.5.1 Census incompletness and uncertainty There are two main problems we can encounter when dealing with census data. It is possible that some variables that we may want to use for poststratification are not available. For instance, party ID is not registered in the US census and ethnicity is not registered in the French census. This additional information can be included in the poststratification table based on other (generally smaller) surveys that contain these variables. A great number of demogaphic-geographic combinations can require a large poststratification table, which in turn can result in unreliable census estimates. The American Community Survey we use in this case study does not only provide estimates of the actual figures that would have been obtained if the entire population was sampled, it also includes a measure of uncertainty around these estimates. Ideally, this uncertainty should be taken into account in the poststratification. For simplicity, this introduction has skipped this step, but this could mean the MRP-based estimates present an underestimated uncertainty. 2.5.2 Nonreponse and missing data We have seen that MRP is a method that can mitigate potential biases in the sample, but it is not a substitute for a better data collection effort that tries to minimize systematic nonresponse patterns. 2.5.3 Model complexity MRP depends upon the use of a regularized model (i.e. that prevents overfitting by limiting its complexity). Different approaches can be used for this goal (e.g. non-multilevel regression, random forests, or a neural network; see Bisbee (2019) for an implementation that uses Bayesian Additive Regression Trees), but there are several advantages of using a Bayesian multilevel model. First, the multilevel structure allows for partially pooling information across different levels of a factor, which can be crucial when dealing with certain levels with few samples. Second, the Bayesian approach propagates uncertainty across the modeling, and thus gives more realistic confidence intervals. Apart from selecting the factors included in the poststratification table, there are several decisions the modeler should make. As we have already mentioned, adding relevant state-level predictors to the model often improves results, particularly when we have few data about some states. The inclusion of interactions can also be benefitial, especially when studying subgroups within subgroups (e.g. demographic subgroups within states; Ghitza and Gelman (2013)). Lastly, the use of structured priors can also serve to reduce both bias and variance by sharing information across the levels of a factor (Gao et al. (2020)). 2.5.4 Empty cells in the poststratification table It is very frequent that some of the cells in the poststratification table are empty, meaning that there are not anyone that fulfills some specific combination of factors. For instance, in a given poststratification table we might find that there can be no people younger than 20, without a high school degree, and earning more than $500,000 a year in a particularly small state. In our example, we made sure that all the cells in the poststratification table were present even if the weight of that cell was zero, but this was only for illustrative purposes. 2.5.5 Subnational units not represented in the survey It is fairly common for small-sample surveys not to include anyone from a particular subnational unit. For instance, a small national survey in the US may not include any participant from Wyoming. An important advantage of MRP is that we can still produce estimates for this state using the information from the participants in other states. Going back to the first parametrization of the multilevel model that we presented, \\(\\alpha^{\\rm state}_{\\rm s = Wyoming}\\) will be calculated based on the region and Republican voteshare of the 2016  even in the abscence of information about the effect of residing in Wyoming specifically. As we have already explained, including subnational-level predictors is always recommended, particularly considering that data at the subnational level is easy to obtain in many cases. However, when dealing with subnational units that are not represented in our survey these predictors become even more central, as they are able to capture structured differences among the states and therefore allow for more precise estimation in the missing subnational areas. 2.5.6 Computational issues Stan uses Hamiltonian Monte Carlo to explore the posterior distribution. In some cases, the geometry of the posterior distribution is too complex, making the Hamiltonian Monte Carlo diverge. This produces a warning indicating the presence of divergent transitions after warmup, something that implies the model could present biased estimates (see Betancourt (2017) for more details). Usually, a few divergent transitions do not indicate a serious problem. There are, in any case, three potential solutions to this problem that do not involve reformulating the model: (i) a non-centered parametization; (ii) increasing the adapt_delta parameter; and (iii) including stronger priors. Fortunately we dont have to worry about (i), as rstanarm already provides a non-centered parametization for the model. Therefore, we can focus on the other two. Exploring the posterior distribution is somewhat similar as cartographing a mountainous terrain, and a divergent transition is similar to falling down a very steep slope, with the consequence of not being able to correctly map that area. In this analogy, what the cartographer could do is moving through the steep slope giving smaller steps to avoid falling. In Stan, the step size is set up automatically, but we can change a parameter called adapt_delta that controls the step size. By default we have that adapt_delta = .95, but we can increase that number to make Stan take smaller steps, which should reduce the number of divergent transitions. The maximum value we can set for adapt_delta is close (but necessarely less than) 1, with the downside that an increase implies a somewhat slower exploration of the posterior distribution. Usually, an adapt_delta = 0.99 works well if we only have a few divergent transitions. However, there are cases in which increasing adapt_delta is not sufficient, and divergent transitions still occur. In this case, introducing weakly informative priors can be extremelly helpful. Although rstanarm provides by default weakly informative priors, in most applications these tend to be too weak. By using more reasonable priors, we make the posterior distribution easier to explore. The priors for the scaled coefficients are \\({\\rm Normal}(0, 2.5)\\). When the coefficients are not scaled, rstanarm will automatically adjust the scaling of the priors as detailed in the prior vignette. In most cases, and particularly when we find computational issues, it is reasonable to give stronger priors on the scaled coefficients such as \\({\\rm Normal}(0, 1)\\). Multilevel models with multiple group-level standard deviation parameters (e.g. \\(\\sigma^{\\rm age}\\), \\(\\sigma^{\\rm eth}\\), \\(\\sigma^{\\rm educ.eth}\\), etc.) tend to be hard to estimate and sometimes present serious computational issues. The default prior for the covariance matrix is decov(reg. = 1, conc. = 1, shape = 1, scale = 1). However, in a varying-intercept model such as this one (i.e. with structure (1 | a) + (1 | b) + ... + (1 | n)) the group-level standard deviations are independent of each other, and therefore the prior is simply a gamma distribution with some shape and scale. Consequently, decov(shape = 1, scale = 1) implies a weakly informative prior \\({\\rm Gamma(shape = 1, scale = 1)} = {\\rm Exponential(scale = 1)}\\) on each group-level standard deviation. This is too weak in most situations, and using something like \\({\\rm Exponential(scale = 0.5)}\\) can be crucial for stabilizing computation. Therefore, something like this has much fewer chances of running into computational issues than simply leaving the defaults: fit &lt;- stan_glmer(abortion ~ (1 | state) + (1 | eth) + (1 | educ) + (1 | age) + male + (1 | male:eth) + (1 | educ:age) + (1 | educ:eth) + repvote + factor(region), family = binomial(link = &quot;logit&quot;), data = df, prior = normal(0, 1, autoscale = TRUE), prior_covariance = decov(scale = 0.50), adapt_delta = 0.99, refresh = 0, seed = 1010) More details about divergent transitions can be found in the Brief Guide to Stans Warnings and in the Stan Reference Manual. More information and references about priors can be found in the Prior Choice Recommendations Wiki. 2.6 Appendix: Data Preprocessing for CCES and Census Data 2.6.1 CCES The code below shows in more detail how the processing of the CCES was done. Notice that age, a continous variable, is split into different levels, and that the levels of some factors are modified in order to match the ACS data. clean_cces &lt;- function(df, list_states_abb, list_states_num){ ## Abortion -- dichotomous (0 - Oppose / 1 - Support) df$abortion &lt;- abs(df$CC18_321a-2) ## State -- factor df$state &lt;- df$inputstate df$state &lt;- factor(df$state, levels = list_states_num, labels = list_states_abb) ## Gender -- dichotomous coded as -0.5 Female and +0.5 Male, as this allows for an intercept that represents a ## &#39;midway&#39; point between the two groups. df$male &lt;- abs(df$gender-2) ## Ethnicity -- factor df$eth &lt;- factor(df$eth, levels = 1:8, labels = c(&quot;White&quot;, &quot;Black&quot;, &quot;Hispanic&quot;, &quot;Asian&quot;, &quot;Native American&quot;, &quot;Mixed&quot;, &quot;Other&quot;, &quot;Middle Eastern&quot;)) df$eth &lt;- fct_collapse(df$eth, &quot;Other&quot; = c(&quot;Asian&quot;, &quot;Other&quot;, &quot;Middle Eastern&quot;, &quot;Mixed&quot;, &quot;Native American&quot;)) ## Age -- cut into factor df$age &lt;- 2018 - df$birthyr df$age &lt;- cut(as.integer(df$age), breaks = c(0, 29, 39, 49, 59, 69, 120), labels = c(&quot;18-29&quot;,&quot;30-39&quot;,&quot;40-49&quot;,&quot;50-59&quot;,&quot;60-69&quot;,&quot;70+&quot;), ordered_result = TRUE) ## Education -- factor df$educ &lt;- factor(as.integer(df$educ), levels = 1:6, labels = c(&quot;No HS&quot;, &quot;HS&quot;, &quot;Some college&quot;, &quot;Associates&quot;, &quot;4-Year College&quot;, &quot;Post-grad&quot;), ordered = TRUE) df$educ &lt;- fct_collapse(df$educ, &quot;Some college&quot; = c(&quot;Some college&quot;, &quot;Associates&quot;)) # Clean and remove NAs df &lt;- df %&gt;% select(abortion, state, eth, male, age, educ) %&gt;% drop_na() } 2.6.2 American Community Survey We start downloading the Public Use Microdata Sample from the American Community Survey data repository. The repository contains two .zip files corresponding to each state: one for individual-level variables and other for household-level variables. All the variables considered in our analysis are available in the individual-level files, but we will also download and process the household-level variable income to show how this could be done. dir.create(&quot;postrat_data/&quot;) system(&#39;wget -O postrat_data -e robots=off -nd -A &quot;csv_*.zip&quot; -R &quot;index.html&quot;,&quot;csv_hus.zip&quot;,&quot;csv_pus.zip&quot; https://www2.census.gov/programs-surveys/acs/data/pums/2018/5-Year/&#39;) Once we have the dataset, there are two main considerations: Focus on the population of interest: We must take into account that the population of interest for the CCES survey, which only considers US citizens above 18 years of age, is different from the population reflected in the ACS. Therefore, we had to remove the cases of underages and non-US citizens in the ACS. Match the levels of the two datasets: The levels of the variables in the poststratification table must match the levels of the variables in the CCES dataset. In this case, this required preprocessing the variables of the CCES and ACS in a way that the levels were compatible. list_states_abb &lt;- datasets::state.abb list_states_num &lt;- rep(NA, length(list_states_abb)) list_of_postrat_df &lt;- list() for(i in 1:length(list_states_num)){ # Unzip and read household and person files for state i p_name &lt;- paste0(&quot;postrat_data/csv_p&quot;, tolower(list_states_abb[i]),&quot;.zip&quot;) h_name &lt;- paste0(&quot;postrat_data/csv_h&quot;, tolower(list_states_abb[i]),&quot;.zip&quot;) p_csv_name &lt;- grep(&#39;\\\\.csv$&#39;, unzip(p_name, list=TRUE)$Name, ignore.case=TRUE, value=TRUE) temp_df_p_state &lt;- fread(unzip(p_name, files = p_csv_name), header=TRUE, select=c(&quot;SERIALNO&quot;,&quot;ST&quot;,&quot;CIT&quot;,&quot;PWGTP&quot;,&quot;RAC1P&quot;,&quot;HISP&quot;,&quot;SEX&quot;,&quot;AGEP&quot;, &quot;SCHL&quot;)) h_csv_name &lt;- grep(&#39;\\\\.csv$&#39;, unzip(h_name, list=TRUE)$Name, ignore.case=TRUE, value=TRUE) temp_df_h_state &lt;- fread(unzip(h_name, files = h_csv_name), header=TRUE, select=c(&quot;SERIALNO&quot;,&quot;FINCP&quot;)) # Merge the individual and household level variables according to the serial number temp_df &lt;- merge(temp_df_h_state, temp_df_p_state, by = &quot;SERIALNO&quot;) # Update list of state numbers that will be used later list_states_num[i] &lt;- temp_df$ST[1] ## Filter by citizenship temp_df &lt;- temp_df %&gt;% filter(CIT!=5) ## State temp_df$state &lt;- temp_df$ST ## Gender temp_df$male &lt;- abs(temp_df$SEX-2)-0.5 ## ethnicity temp_df$RAC1P &lt;- factor(temp_df$RAC1P, levels = 1:9, labels = c(&quot;White&quot;, &quot;Black&quot;, &quot;Native Indian&quot;, &quot;Native Alaskan&quot;, &quot;Native Indian or Alaskan&quot;, &quot;Asian&quot;, &quot;Pacific Islander&quot;, &quot;Other&quot;, &quot;Mixed&quot;)) temp_df$eth &lt;- fct_collapse(temp_df$RAC1P, &quot;Native American&quot; = c(&quot;Native Indian&quot;, &quot;Native Alaskan&quot;, &quot;Native Indian or Alaskan&quot;)) temp_df$eth &lt;- fct_collapse(temp_df$eth, &quot;Other&quot; = c(&quot;Asian&quot;, &quot;Pacific Islander&quot;, &quot;Other&quot;, &quot;Native American&quot;, &quot;Mixed&quot;)) levels(temp_df$eth) &lt;- c(levels(temp_df$eth), &quot;Hispanic&quot;) temp_df$eth[(temp_df$HISP!=1) &amp; temp_df$eth==&quot;White&quot;] &lt;- &quot;Hispanic&quot; ## Age temp_df$age &lt;- cut(as.integer(temp_df$AGEP), breaks = c(0, 17, 29, 39, 49, 59, 69, 120), labels = c(&quot;0-17&quot;, &quot;18-29&quot;,&quot;30-39&quot;,&quot;40-49&quot;,&quot;50-59&quot;,&quot;60-69&quot;,&quot;70+&quot;), ordered_result = TRUE) ## Filter out underages temp_df &lt;- filter(temp_df, age!=&quot;0-17&quot;) temp_df$age &lt;- droplevels(temp_df$age) ## Income (not currently used) temp_df$income &lt;- cut(as.integer(temp_df$FINCP), breaks = c(-Inf, 9999, 19999, 29999, 39999, 49999, 59999, 69999, 79999, 99999, 119999, 149999, 199999, 249999, 349999, 499999, Inf), ordered_result = TRUE, labels = c(&quot;&lt;$10,000&quot;, &quot;$10,000 - $19,999&quot;, &quot;$20,000 - $29,999&quot;, &quot;$30,000 - $39,999&quot;, &quot;$40,000 - $49,999&quot;, &quot;$50,000 - $59,999&quot;, &quot;$60,000 - $69,999&quot;, &quot;$70,000 - $79,999&quot;,&quot;$80,000 - $99,999&quot;, &quot;$100,000 - $119,999&quot;, &quot;$120,000 - $149,999&quot;, &quot;$150,000 - $199,999&quot;,&quot;$200,000 - $249,999&quot;, &quot;$250,000 - $349,999&quot;, &quot;$350,000 - $499,999&quot;, &quot;&gt;$500,000&quot;)) temp_df$income &lt;- fct_explicit_na(temp_df$income, &quot;Prefer Not to Say&quot;) ## Education temp_df$educ &lt;- cut(as.integer(temp_df$SCHL), breaks = c(0, 15, 17, 19, 20, 21, 24), ordered_result = TRUE, labels = c(&quot;No HS&quot;, &quot;HS&quot;, &quot;Some college&quot;, &quot;Associates&quot;, &quot;4-Year College&quot;, &quot;Post-grad&quot;)) temp_df$educ &lt;- fct_collapse(temp_df$educ, &quot;Some college&quot; = c(&quot;Some college&quot;, &quot;Associates&quot;)) # Calculate the poststratification table temp_df &lt;- temp_df %&gt;% drop_na(state, eth, male, age, educ, PWGTP) %&gt;% select(state, eth, male, age, educ, PWGTP) ## Trick to &#39;expand&#39; the poststratification table so groupby produces all the rows, even the ones with N = 0 temp_df_expanded &lt;- temp_df %&gt;% expand(state, eth, male, age, educ) %&gt;% mutate(PWGTP = 0) temp_df &lt;- rbind(temp_df, temp_df_expanded) ## We sum by the inidividual-level weight PWGTP list_of_postrat_df[[i]] &lt;- temp_df %&gt;% group_by(state, eth, male, age, educ, .drop = FALSE) %&gt;% summarise(n = sum(as.numeric(PWGTP))) print(paste0(list_states_abb[i], &quot; completed&quot;)) } postrat_df &lt;- rbindlist(list_of_postrat_df) write.csv(postrat_df, &quot;postrat_data.csv&quot;) #library(ipumsr) #ddi &lt;- read_ipums_ddi(&#39;C:/Users/Juanl/Documents/GDrive/Columbia/0.Summer/gelman/usa_00001.xml&#39;) #acs &lt;- read_ipums_micro(ddi, data_file = &#39;C:/Users/Juanl/Documents/GDrive/Columbia/0.Summer/gelman/usa_00001.dat&#39;) References "],["mrp-with-noncensus-variables.html", "Chapter 3 MRP with Noncensus Variables 3.1 Model-based Extension of the Poststratification Table 3.2 Adjusting for Nonresponse Bias 3.3 Obtaining Estimates for Non-census Variable Subgroups", " Chapter 3 MRP with Noncensus Variables h1.title { font-size: 32px; text-align: center; } h2 { padding-bottom: 4px; } h4.author { padding-top: 22px; text-align: center; font-style: italic; } h4.date { padding-top: 14px; font-size: 14px; text-align: center; font-style: italic; padding-bottom: 20px; } #myDIV { width: 100%; padding: 20px 30px; background-color: rgba(192,192,192,0.15); margin-top: 10px; border-radius: 4px; } #myButton{ border-color: #008CBA; background-color: rgba(192,192,192,0.05); color: #008CBA; border-radius: 4px; } #myDIV2 { width: 100%; padding: 20px 30px; background-color: rgba(192,192,192,0.15); margin-top: 10px; border-radius: 4px; } #myButton2{ border-color: #008CBA; background-color: rgba(192,192,192,0.05); color: #008CBA; border-radius: 4px; } #myDIV3 { width: 100%; padding: 20px 30px; background-color: rgba(192,192,192,0.15); margin-top: 10px; border-radius: 4px; } #myButton3{ border-color: #008CBA; background-color: rgba(192,192,192,0.05); color: #008CBA; border-radius: 4px; } When our sample population is different than our target population, MRP can only adjust for the predictors included in the model. As these are restricted by the variables in the poststratification table, which in turn are limited by the questions asked in the census, the characteristics that we can use for poststratification are quite reduced. This is the reason researchers tend to use simple demographic and geographic variables, which unfortunately do not provide much help if the bias in the survey originates from non-response in voters of a certain party, for instance. As a potential solution, Kastellec et al. (2015) propose extending the postratification table using a survey that contains one or multiple non-census variables that could help adjusting for the differences between the sample and the target population. For instance, if our survey asked for partisanship, we could use the CCES to extend the poststratification table such as that it also contains this variable. The extension is done in two steps. First, we fit a multilevel model in which we try to predict partisanship in the CCES based on the variables available in the census. Second, we use this model to predict, for each cell in the original poststratification table, what proportion of subjects are Democrats, Republicans, or Independents. This extended poststratification table that contains partisanship will allow us to (a) generate MRP estimates that adjust for differential party nonresponse in the original survey; and/or (b) obtain estimates outcome of interest by party. For this case study we will continue using the previous example of studying support for the right of employers to exclude abortion coverage. ## Read CCES data with the same outcome variable and predictors, but also including ## party df_all &lt;- read.csv(&quot;cces18_common_vv.csv&quot;) list_states_abb &lt;- datasets::state.abb list_states_num &lt;- c(1,2,4,5,6,8,9,10,12,13,15,16,17,18,19,20,21,22,23,24,25,26, 27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,44,45,46,47, 48,49,50,51,53,54,55,56) # Preprocessing. The clean_cces2 function also reads party df_all &lt;- clean_cces2(df_all, list_states_abb, list_states_num) ## Read poststratification table poststrat_df &lt;- read.csv(&quot;postrat_data.csv&quot;) poststrat_df$state &lt;- factor(poststrat_df$state, levels = list_states_num, labels = list_states_abb) ## Read state-level predictors and add them to the CCES and poststratification table statelevel_predictors &lt;- read.csv(&#39;statelevel_predictors.csv&#39;) statelevel_predictors$state &lt;- factor(statelevel_predictors$state, levels = list_states_abb, labels = list_states_abb) df_all &lt;- left_join(df_all, statelevel_predictors, by = &quot;state&quot;, keep = TRUE) poststrat_df &lt;- left_join(poststrat_df, statelevel_predictors, by = &quot;state&quot;, keep = TRUE) 3.1 Model-based Extension of the Poststratification Table As we have described, we start fitting a multilevel model to predict partisanship as a function of the same demographic and geographic variables used in the standard MRP model, which will allow us to predict the proportion of Republicans, Democrats, and Independents in each row of the poststratification table. As there are three levels for partisanship, we use a Bayesian multinomial (i.e. unordered) logistic regression which can be fitted in brms (currently, rstanarm does not support multinomial logistic regression). For this extension step we should use a survey that we think is to some degree representative with respect to the variable that we are trying to include in the poststratification table. In our example, if we extended our census-based poststratification table using a highly non-representative survey with respect to party, we would indeed generated a biased poststratification table and ultimately obtain compromised MRP estimates. In other words, this is our opportunity to bring outside information in order to generate a richer poststratification table that can adjust for potential biases in the main survey, so we need to make sure that the survey we use to extend the poststratification table is trustworthy with respect to the non-census variable. In this example, we will use a 5,000-person sample of the CCES to extend the poststratification table to include partisanship, which is addressed in the CCES: Generally speaking, do you think of yourself as a ? (Democrat, Republican, Independent, Other, Not Sure) For simplicity, we included the few respondents that indicated Other or Not Sure as Independents. # Setting seed to arbitrary number for reproducibility set.seed(1010) # Taking random sample from the CCES survey df_random &lt;- df_all %&gt;% sample_n(5000) # fit_party &lt;- brm(party ~ (1 | state) + (1 | eth) + (1 | age) + (1 | educ) + male + # (1 | male:eth) + (1 | educ:age) + (1 | educ:eth) + # repvote + factor(region), # family = &quot;categorical&quot;, # data = df_random, # prior = c(prior(normal(0, 5), class = Intercept), # prior(normal(0, 1), class = b), # prior(exponential(0.5), class = sd, dpar = muIndependent), # prior(exponential(0.5), class = sd, dpar = muRepublican)), # control = list(adapt_delta = 0.9, max_treedepth = 10), # seed = 1010) # # saveRDS(fit_party, file = &quot;fit_party_example.rds&quot;) fit_party &lt;- readRDS(&quot;fit_party_example.rds&quot;) This model gives us, for each poststratification cell \\(j\\), an estimate for the proportion of Democrats (\\(\\hat{\\theta}_{{\\rm Democrat}, j}\\)), Republicans (\\(\\hat{\\theta}_{{\\rm Republican}, j}\\)), and Independents (\\(\\hat{\\theta}_{{\\rm Independent}, j}\\)). We can multiply these quantities by the number of people in cell \\(j\\) to estimate the number of Democrats (\\(N_j \\: \\hat{\\theta}_{{\\rm Democrat}, j}\\)), Republicans (\\(N_j \\: \\hat{\\theta}_{{\\rm Republican}, j}\\)), and Independents (\\(N_j \\: \\hat{\\theta}_{{\\rm Independent}, j}\\)), obtaining an extended poststratification table in which each cell has been expanded into three. That is, if the original poststratification table had \\(J\\) rows (e.g. 12,000 in our case), the new one will have \\(3 J\\) (e.g. 36,000). There is, however, a certain complication that must be taken into account. The model-based estimates for the proportion of Democrats, Republicans, and Independents are not single numbers, but several draws from the posterior distribution that capture the uncertainty about these estimates. For instance, if we have 500 draws for \\(\\hat{\\theta}_{{\\rm Democrat}, j}\\), \\(\\hat{\\theta}_{{\\rm Republican}, j}\\), and \\(\\hat{\\theta}_{{\\rm Independent}, j}\\), we can imagine 500 poststratification tables with different numbers for each cell. ## Use pp_expect to predict partisanship for original poststratification table posmat_party &lt;- pp_expect(fit_party, newdata = poststrat_df, transform = TRUE) # pp_expect does not allow us to select the number of draws. Therefore, we # take a random sample of 500 draws from posterior distribution posmat_party &lt;- posmat_party[sample(nrow(posmat_party), size=500, replace=TRUE),,] # Extend poststratification table poststrat_df_threefold &lt;- poststrat_df[rep(seq_len(nrow(poststrat_df)), each = 3), ] poststrat_df_threefold$party &lt;- rep(c(&quot;Democrat&quot;, &quot;Republican&quot;, &quot;Independent&quot;), nrow(poststrat_df)) # Calculate new numbers for the cells of the new poststratification table. K # is a matrix containing 36000 rows (one for each cell of the poststratification table) # and 500 columns (corresponding to the 500 draws). K_theta &lt;- apply(posmat_party, 1, function(x){as.vector(t(x))}) K &lt;- K_theta * rep(poststrat_df$n, each = 3) Show code explanation More generally, lets say that for each \\(\\hat{\\theta}_{{\\rm Democrat}, j}\\), \\(\\hat{\\theta}_{{\\rm Republican}, j}\\), and \\(\\hat{\\theta}_{{\\rm Independent}, j}\\) we have a vector that contains \\(D_1\\) draws from the posterior distribution. In the code \\(D_1 = 500\\), as we have randomly selected 500 draws from the posmat_party matrix. Therefore, pp_expect (the brms equivalent to posterior_epred) will return an array with \\(J\\) (number of rows of the original poststratification table) \\(\\times D_1\\) (number of draws from posterior distribution) \\(\\times 3\\) (estimates for Democrats, Republicans, and Independents) dimensions. The first step is to take this \\(J \\times D_1 \\times 3\\) array and transform it to a \\(3J \\times D_1\\) matrix. Then, we multiply each row of the matrix by the corresponding \\(N_j\\) of the original poststratification table. This gives us a new \\(3J \\times D_1\\) matrix that we will call \\(K\\), and which contains the \\(D_1\\) draws for each of the \\(3J\\) cells of the new poststratification table. In sum, we started with a poststratification table with 12,000 rows. Here we can see the first three rows: state eth male age educ n AL White -0.5 18-29 No HS 23948 AL White -0.5 18-29 HS 59378 AL White -0.5 18-29 Some college 104855 We have used a model-based approach to include partisanship in this poststratification table, that now has 36,000 rows (again, each row in the original table has been split into three). However, in order to consider the uncertainty in these model-based estimates we have actually built 500 different poststratification tables. Here we show the first 9 rows of one of these 500 poststratification tables: state eth male age educ party n AL White -0.5 18-29 No HS Democrat 2937.5 AL White -0.5 18-29 No HS Republican 11304.4 AL White -0.5 18-29 No HS Independent 9706.1 AL White -0.5 18-29 HS Democrat 11157.6 AL White -0.5 18-29 HS Republican 27019.1 AL White -0.5 18-29 HS Independent 21201.3 AL White -0.5 18-29 Some college Democrat 22402.2 AL White -0.5 18-29 Some college Republican 44411.2 AL White -0.5 18-29 Some college Independent 38041.6 3.2 Adjusting for Nonresponse Bias We have described how to extend the poststratification table by including partisanship. Now, we will use this poststratification table to adjust for differential party nonresponse. 3.2.1 Setting up example with an artificially nonrepresentative sample To demostraty how non-census MRP can adjust for party, we will use a survey that is biased with respect to party. As we are already familiar with the CCES dataset, what we are going to do is to take a different sample of 5,000 respondents that simulates a high nonresponse rate among Republicans and, to a lesser degree, Independents. # Random sample of 5,000 that weights by party df_nonrepresentative &lt;- df_all %&gt;% sample_n(5000, weight = I((df_all$party==&quot;Democrat&quot;)*1 + (df_all$party==&quot;Independent&quot;)*0.75 + (df_all$party==&quot;Republican&quot;)*0.5)) Previously, we saw that the national average support for requiring companies to cover abortion in their insurance plans was around 43.4% according to the CCES. Comparatively, this biased sample of the CCES gives an estimate of 36.7%. This is not surprising, as missing Republicans and Independents in the survey should reduce support for the employers right to decline abortion coverage. 3.2.2 Standard MRP We fit a standard MRP (i.e. without including party) on the nonrepresentative sample, using the same model as in the MRP introduction and the non-extended poststratification table. # fit_abortion_standard &lt;- stan_glmer(abortion ~ (1 | state) + (1 | eth) + (1 | age) + (1 | educ) + male + # (1 | male:eth) + (1 | educ:age) + (1 | educ:eth) + # repvote + factor(region), # family = binomial(link = &quot;logit&quot;), # data = df_nonrepresentative, # prior = normal(0, 1, autoscale = TRUE), # prior_covariance = decov(scale = 0.50), # adapt_delta = 0.99, # seed = 1010) # # saveRDS(fit_abortion_standard, file = &quot;fit_abortionstandard_example.rds&quot;) fit_abortion_standard &lt;- readRDS(&quot;fit_abortionstandard_example.rds&quot;) P_standardMRP &lt;- rstanarm::posterior_epred(fit_abortion_standard, newdata = poststrat_df, draws = 500) national_standardMRP &lt;- (P_standardMRP %*% poststrat_df$n)/sum(poststrat_df$n) The standard MRP with the nonrepresentative sample gives a national-level estimate of 38.7% (\\(\\pm\\) 0.7%). As this estimate does not consider partisanship, standard MRP is not being able to adjust for the smaller statement support that results from oversampling Democrats. 3.2.3 Non-census MRP with partisanship as a predictor In the first section we have created a poststratification table that contains partisanship. After doing this, the next step of the non-census MRP approach is to fit the same model as we did in the standard MRP, but also including party as a predictor: \\[ Pr(y_i = 1) = logit^{-1}( \\alpha_{\\rm s[i]}^{\\rm state} + \\alpha_{\\rm a[i]}^{\\rm age} + \\alpha_{\\rm r[i]}^{\\rm eth} + \\alpha_{\\rm e[i]}^{\\rm educ} + \\beta^{\\rm male} \\cdot {\\rm Male}_{\\rm i} + \\alpha_{\\rm g[i], r[i]}^{\\rm male.eth} + \\alpha_{\\rm e[i], a[i]}^{\\rm educ.age} + \\alpha_{\\rm e[i], r[i]}^{\\rm educ.eth} + \\alpha_{\\rm p[i]}^{\\rm party} ) \\] \\[ \\begin{align*} \\alpha_{\\rm s}^{\\rm state} &amp;\\sim {\\rm Normal}(\\gamma^0 + \\gamma^{\\rm south} \\cdot {\\rm South}_{\\rm s} + \\gamma^{\\rm midwest} \\cdot {\\rm Midwest}_{\\rm s} + \\gamma^{\\rm west} \\cdot {\\rm West}_{\\rm s} + \\gamma^{\\rm repvote} \\cdot {\\rm RepVote}_{\\rm s}, \\sigma_{\\rm state}) \\textrm{ for s = 1,...,50}\\\\ \\alpha_{\\rm a}^{\\rm age} &amp; \\sim {\\rm Normal}(0,\\sigma_{\\rm age}) \\textrm{ for a = 1,...,6}\\\\ \\alpha_{\\rm r}^{\\rm eth} &amp; \\sim {\\rm Normal}(0,\\sigma_{\\rm eth}) \\textrm{ for r = 1,...,4}\\\\ \\alpha_{\\rm e}^{\\rm educ} &amp; \\sim {\\rm Normal}(0,\\sigma_{\\rm educ}) \\textrm{ for e = 1,...,5}\\\\ \\alpha_{\\rm g,r}^{\\rm male.eth} &amp; \\sim {\\rm Normal}(0,\\sigma_{\\rm male.eth}) \\textrm{ for g = 1,2 and r = 1,...,4}\\\\ \\alpha_{\\rm e,a}^{\\rm educ.age} &amp; \\sim {\\rm Normal}(0,\\sigma_{\\rm educ.age}) \\textrm{ for e = 1,...,5 and a = 1,...,6}\\\\ \\alpha_{\\rm e,r}^{\\rm educ.eth} &amp; \\sim {\\rm Normal}(0,\\sigma_{\\rm educ.eth}) \\textrm{ for e = 1,...,5 and r = 1,...,4}\\\\ \\alpha_{\\rm p}^{\\rm party} &amp; \\sim {\\rm Normal}(0,\\sigma_{\\rm party}) \\textrm{ for p = 1,2,3}\\\\ \\end{align*} \\] # fit_abortion_noncensus &lt;- stan_glmer(abortion ~ (1 | state) + (1 | eth) + (1 | age) + (1 | educ) + male + # (1 | male:eth) + (1 | educ:age) + (1 | educ:eth) + # repvote + factor(region) + (1 | party), # family = binomial(link = &quot;logit&quot;), # data = df_nonrepresentative, # prior = normal(0, 1, autoscale = TRUE), # prior_covariance = decov(scale = 0.50), # adapt_delta = 0.99, # seed = 1010) # # saveRDS(fit_abortion_noncensus, file = &quot;fit_abortionnoncensus_example.rds&quot;) fit_abortion_noncensus &lt;- readRDS(&quot;fit_abortionnoncensus_example.rds&quot;) Using posterior_epred allows us to estimate abortion coverage support for each of the cells in the extended poststratification table. As we set draws = 500, we obtain 500 estimates for each cell. In standard MRP, we will weight each the statement support estimates for each poststratification cell by the number of people in that cell according to the model-based estimates obtained in the previous section. However, as in this case the number of people in each cell was estimated with uncertainty, we need to propagate the uncertainty in the first (party prediction) model to the final MRP estimates. Essentially, what we can do is randomly pick one of the 500 statement support estimates for each poststratification cell (i.e. a 36,000 vector) we have just obtained and weight it by one of the 500 poststratification tables that resulted from the first model. Repeating the process for the remaining draws gives us a distribution of 500 MRP estimates for national support that correctly captures the uncertainty in the two models. # Use posterior_epred to predict stance on abortion insurance coverage for extended poststratification table P &lt;- rstanarm::posterior_epred(fit_abortion_noncensus, newdata = poststrat_df_threefold, draws = 500) # Calculate national MRP estimates propagating uncertainty from the two models national_noncensusMRP &lt;- colSums(t(P)*K) / sum(K[,1]) Show code explanation More generally, posterior_epred returns a \\(D_2 \\times 3J\\) matrix we name \\(P\\), where \\(D_2\\) is the number of draws and \\(3J\\) is, again, the number of cells in the extended poststratification table that includes partisanship. With the two matrices \\(P\\) a \\(K\\), the poststratification step becomes: \\[\\hat{\\theta}_{MRP} = \\frac{P \\times K}{\\sum_j^{3J} k_{j 1}} {\\rm \\: where \\:} K = (k_{jd})\\] Were \\(\\hat{\\theta}_{MRP}\\) is a matrix containing \\(D_2 \\times D_1\\) estimates for the proportion of statement support. In case of \\(D_1 = D_2\\), we can do an elementwise operation such that \\(\\hat{\\theta}_{MRP} = \\frac{\\sum_j^{3J} (P^T \\odot K)_{jd}}{\\sum_j^{3J} k_{j1}}\\) in order for the operation to be less computationally expensive, as we only combine each draw (i.e. column) in matrix \\(P\\) with one draw (i.e. column) in matrix \\(K\\) (instead with all the draws in matrix \\(K\\)). This more efficient method, which is the one we implement, returns a vector of length \\(D_1 = D_2\\). The only consideration is that we must make sure that \\(D_1 = D_2\\), which in this case required randomly picking 500 draws from \\(K\\) and only obtaining another 500 draws for \\(P\\) (by specifying draws = 500). Our national-level estimate for the right to exclude abortion coverage from employer-sponsored insurance resulting from this non-census variable MRP is 43.1% (0.7%). Unsurprisingly, this is much closer to the full (unbiased) 60,000 participant survey (43.4 \\(\\pm\\) 0.2%) than the standard MRP estimate (38.7 \\(\\pm\\) 0.7%). Using an extended poststratification table that contained partisanship allowed us to adjust for differential partisan nonresponse. Of course, we can also obtain state-level estimates and compare standard MRP with non-census MRP. n_states &lt;- length(unique(poststrat_df_threefold$state)) state_df &lt;- data.frame( state = rep(NA, n_states), standardMRP_mean = rep(NA, n_states), standardMRP_se = rep(NA, n_states), noncensusMRP_mean = rep(NA, n_states), noncensusMRP_se = rep(NA, n_states), all_mean = rep(NA, n_states), all_se = rep(NA, n_states) ) for(i in 1:n_states){ state &lt;- unique(poststrat_df_threefold$state)[i] state_df$state[i] &lt;- as.character(state) standardMRP_vector &lt;- (P_standardMRP[, poststrat_df$state==state] %*% poststrat_df[poststrat_df$state==state, &quot;n&quot;])/ sum(poststrat_df[poststrat_df$state==state, &quot;n&quot;]) state_df$standardMRP_mean[i] &lt;- mean(standardMRP_vector) state_df$standardMRP_se[i] &lt;- sd(standardMRP_vector) noncensusMRP_vector &lt;- colSums(t(P[ ,poststrat_df_threefold$state==state]) * K[poststrat_df_threefold$state==state, ]) / sum(K[poststrat_df_threefold$state==state, 1]) state_df$noncensusMRP_mean[i] &lt;- mean(noncensusMRP_vector) state_df$noncensusMRP_se[i] &lt;- sd(noncensusMRP_vector) state_df$all_mean[i] &lt;- mean(df_all[df_all$state==state,&quot;abortion&quot;]) state_df$all_se[i] &lt;- sqrt(state_df$all_mean[i]*(1-state_df$all_mean[i])/nrow(df_all[df_all$state==state,])) } In general, we see that the estimates from the standard MRP are upwardly biased with respect to the 60,000 survey estimates. Conversely, the MRP with non-census variables is able to adjust for the differential partisan nonresponse. 3.3 Obtaining Estimates for Non-census Variable Subgroups Even if we do not suspect that our survey population is different from our target population with respect to a non-census variable, using non-census MRP can allow us to obtain different estimates for the levels of the non-census variable. Here, we obtain and plot support for declining coverage of abortions by state and party within state. state_df &lt;- df_nonrepresentative %&gt;% expand(state, party) %&gt;% mutate(model_mean = NA, model_sd = NA) for(i in 1:nrow(state_df)){ filtering_condition &lt;- which(poststrat_df_threefold$state == state_df$state[i] &amp; poststrat_df_threefold$party == state_df$party[i]) noncensusMRP_vector &lt;- colSums(t(P[ ,filtering_condition]) * K[filtering_condition, ]) / sum(K[filtering_condition, 1]) state_df$model_mean[i] &lt;- mean(noncensusMRP_vector) state_df$model_sd[i] &lt;- sd(noncensusMRP_vector) } References "],["ideal-point-mrp.html", "Chapter 4 Ideal Point MRP 4.1 Introduction and Literature 4.2 A Two-Parameter IRT Model with Latent Multilevel Regression 4.3 The Abortion Opposition Index for US States 4.4 Estimating Support for Individual Questions 4.5 Concluding remarks 4.6 Appendix", " Chapter 4 Ideal Point MRP This chapter introduces ideal point MRP, an alternative to standard MRP that can be used when a survey contains at least two related questions that reflect the same attitude or ability. We will present how this method can be used for obtaining sub-national estimates of the latent attitude and also for improving estimates with respect to the individual questions. 4.1 Introduction and Literature 4.1.1 The ABC of IRT Being developed in educational research, ideal point models (also called Item Response Theory models) assume that each participant \\(j\\) has a latent ability \\(\\alpha_j\\). In the context of a math exam, this ability parameter reflects how good a certain student is at math. Of course, \\(\\alpha_j\\) is said to be latent because we do not observe it directly, but only through the students answers to \\(k\\) math-related questions. The ideal point model maps the unobserved ability \\(\\alpha_j\\) to the probability that subject \\(j\\) answers correctly question \\(k\\): \\[ P(y = 1) = logit^{-1}(\\alpha_j - \\beta_k) \\] The probability of correctly answering question \\(k\\) does not only depend on the student ability\\(\\alpha_j\\), but also on the question difficulty \\(\\beta_k\\). Lets imagine one student with \\(\\alpha_1 = 2\\) that answers two questions with difficulties \\(\\beta_1 = 0\\) and \\(\\beta_2 = 3\\). If the case of her answering the first question, we have that there is a \\(logit^{-1}(2 - 0) = 88\\%\\) probability of answering it correctly. In the case of the second question, she has a lower probability of getting it right, in this case \\(logit^{-1}(2 - 3) = 27\\%\\). This is because the second question is much more difficult than the first. If we know take a second student with a lower ability \\(\\alpha_2 = -1.5\\), his probabilities of getting these questions correctly are \\(logit^{-1}(-1.5 - 0) = 18\\%\\) and \\(logit^{-1}(-1.5 - 3) = 1\\%\\). In some situations not every individuals encounters every question. In this case, the ideal point model can be written as \\(P(y_i = 1) = logit^{-1}(\\alpha_{j[i]} - \\beta_{k[i]})\\). In this case, the index \\(i\\) corresponds to the question \\(k[i]\\) responded by the student \\(j[i]\\). Although we will conserve this notation, the data we will use during this case all individuals have responded to all of the questions considered. The above model, which is usually referred as Rasch model or one-parameter model, assumes each question is equally relevant (or discriminatory) to measure the latent ability \\(\\alpha_j\\). Although in educational testing it is desirable to construct questions that are able to discriminate between a student with a low ability and another one with high ability, in practice not all items achieve this to the same extent. This is exactly what the discrimination parameter \\(\\gamma_k\\) reflects. Thus, this extended version that is often called two-parameter ideal point model becomes: \\[ P(y_i = 1) = \\gamma_{k[i]} (logit^{-1}(\\alpha_{j[i]} - \\beta_{k[i]})) \\] Lets consider two questions with equal difficulty \\(\\beta_1 = 0\\) and \\(\\beta_2 = 0\\), but with different discrimination \\(\\gamma_1 = 0.1\\) and \\(\\gamma_2 = 2.5\\). The high-ability student described previously has a \\(logit^{-1}(0.1 \\times (2 - 0) = 55\\%\\) probability of responding correctly to the first question, while the low-ability participant has a \\(logit^{-1}(0.1 \\times (-1.5 - 0) = 46\\%\\) chance. These probabilities are close because this question has a low discrimination parameter, and is therefore not particularly good at distinguishing between high-ability and low-ability individuals. Conversely, the second question has a high discrimination parameter, and therefore the probabilities for these two students are \\(logit^{-1}(1.7 \\times (2 - 0) = 97\\%\\) and \\(logit^{-1}(1.7 \\times (-1.5 - 0) = 7\\%\\), respectively. It is sometimes useful to think about the ideal point model as a function that transforms a latent ability \\(\\alpha_j\\) into the probably of answering correctly a certain question. This mapping depends on the characteristics of the question, which in the case of the two-parameter ideal point model are the difficulty \\(\\beta_k\\) and the discrimination \\(\\gamma_k\\). We can visualize how different values for \\(\\beta_k\\) and \\(\\gamma_k\\) influence this transformation. 4.1.1.1 Multilevel structure and identification The parameters used in the ideal point model are often assumed to follow a multilevel structure that assigns normal distributions to the abilities, difficulties, and discriminations: \\[ \\begin{align} \\alpha_j &amp;\\sim \\text{normal}(\\mu_{\\alpha}, \\sigma_{\\sigma}) \\text{ for } j = 1, ..., J \\\\ \\beta_k &amp;\\sim \\text{normal}(\\mu_{\\beta}, \\sigma_{\\beta}) \\text{ for } k = 1, ..., K \\\\ \\gamma_k &amp;\\sim \\text{normal}(\\mu_{\\gamma}, \\sigma_{\\gamma}) \\text{ for } k = 1, ..., K \\\\ \\end{align} \\] However, the two-parameter ideal point model is not identified. In particular, it suffers from three problems (see Bafumi et al. (2005) for a more detailed discussion on identification problems and solutions): Additive aliasing: Adding a constant to \\(\\alpha_j\\) and \\(\\beta_k\\) will not change its predictions. Multiplicative aliasing: Similarly, multiplying \\(\\gamma_k\\) by a constant and dividing \\((\\alpha_j - beta_j)\\) by the same constant will keep the predictions unchanged. Reflection invariance: Lastly, multiplying the ability, difficulty, and discrimination parameter by -1 will also result in identical predictions. The first two issues can be resolved by creating standardized parameters \\(\\alpha_j^{\\rm adj} = \\frac{\\alpha_j - \\bar{\\alpha}}{s_{\\alpha}}\\), \\(\\beta_k^{\\rm adj} = \\frac{\\beta_k - \\bar{\\alpha}}{s_{\\alpha}}\\), and \\(\\gamma_k^{\\rm adj} = \\gamma_k s_{\\alpha}\\). The new ability, difficulty, and discrimination parameters are well defined and preserve the likelihood as \\(P(y_i = 1) = logit^{-1}(\\gamma_{k[i]}(\\alpha_{j[i]} - \\beta_{k[i]})) = logit^{-1}(\\gamma_{k[i]}^{\\rm adj}(\\alpha_{j[i]}^{\\rm adj} - \\beta_{k[i]}^{\\rm adj}))\\). Reflection invariance can be avoided by restricting \\(\\gamma_k \\gt 0\\) (and consequently \\(\\mu_{\\gamma} \\gt 0\\) and also \\(\\gamma_k^{adj} \\gt 0\\)), which in turn requires precoding the questions so they are in the same direction (i.e. indicating conservative positions). 4.1.1.2 Including predictors for \\(\\alpha_j\\) The mode we have described assumes that the abilities \\(\\alpha_j\\) follow a normal distribution centered at the population average ability \\(\\mu_{\\alpha}\\) with a standard deviation \\(\\sigma_{\\sigma}\\). We can extend this by adding ability-level predictors, resulting in \\(\\alpha_j \\sim \\text{normal}(\\mu_{\\alpha} + X \\beta)\\) where \\(\\mu_{\\alpha}\\) now represents the regression intercept. 4.1.2 Ideal point models and estimating public opinion Until now we have used the example of a math test. However, beyond educational settings an ideal point model can be used to reflect other situations in which a latent characteristic determines a dichotomous response. In the Political Science literature, these models have been famously used to reflect the ideological position of legislators based on their roll call voting records (Clinton, Jackman, and Rivers (2004)). Similarly, we can use the survey respondents support for different statements as reflecting a latent attitude based on a series of survey questions. There have been two main bodies of work that have combined ideal-point models and MRP. Tausanovitch and Warshaw (2013) follow a two-step process to estimate policy preferences across states and cities in the US. First, they fit a unidimensional ideal point model such as the one described by Clinton, Jackman, and Rivers (2004) based on dichotomous responses from the CCES and the ACS, obtaining estimates of the liberalness-conservativeness for 270,000 Americans. Instead of using dissaggregation, the second step involves using an MRP approach that instead of considering the response to any individual question as the outcome they predict this estimated ideal point for each participant. In a later work, Tausanovitch and Warshaw (2014) correlate the city-level policy preference estimates obtained using this method with the policies enacted at the municipal level, finding a clear correspondence. In a related line of work, Caughey and Warshaw (2015) use a conceptually different approach in order to estimate latent abilities over time. First, they model survey responses not at the individual level, but rather at the level of subpopulation groups defined by demographic and geographic characteristics. This has the advantage of using highly sparse data without requiring linking questions that bridge across all the surveys. Second, they extend the model to borrow information across time, which allows to create time-specific estimates of average group opinion. They use this dynamic group-level IRT framework to estimate policy liberalism at the U.S. state level in each year between 1972 and 2012 (for other applications, see Bergquist and Warshaw (2019) and Bergquist and Warshaw (2019)). 4.2 A Two-Parameter IRT Model with Latent Multilevel Regression In the previous two chapters we have only considered one of the questions in the CCES. However, this survey includes six support/oppose statements about abortion: CC18_321a: Always allow a woman to obtain an abortion as a matter of choice. CC18_321b: Permit abortion ONLY in case of rape, incest or when the womans life is in danger. CC18_321c: Ban abortions after the 20th week of pregnancy. CC18_321d: Allow employers to decline coverage of abortions in insurance plans. CC18_321e: Prohibit the expenditure of funds authorized or appropriated by federal law for any abortion. CC18_321f: Make abortions illegal in all circumstances. We can use a two-parameter logistic item response model with a latent (multilevel) regression to model \\(k\\) questions based on \\(j\\) respondents: \\[ \\begin{equation*} P(y_i = 1) = logit^{-1}(\\gamma_{k[i]}^{adj}(\\alpha_{j[i]}^{adj} - \\beta_{k[i]}^{adj})) \\end{equation*} \\] where: \\[ \\begin{align*} \\alpha_j &amp;\\sim {\\rm normal}(\\mu^{\\alpha} + A_{\\rm s[j]}^{\\rm state} + A_{\\rm a[j]}^{\\rm age} + A_{\\rm r[j]}^{\\rm ethnicity} + A_{\\rm e[j]}^{\\rm education} + B^{\\rm male} \\cdot {\\rm Male}_{\\rm j}, \\sigma^{\\alpha}) {\\rm \\ for} \\ j = 1,...,J \\\\ \\beta_k &amp;\\sim {\\rm normal}(\\mu^{\\beta}, \\sigma^{\\beta}) {\\rm \\ for} \\ k = 1,...,K \\\\ \\gamma_k &amp;\\sim {\\rm normal_{+}}(\\mu^{\\gamma}, \\sigma^{\\gamma}) {\\rm \\ for} \\ k = 1,...,K \\end{align*} \\] and: \\[ \\begin{align*} A_{\\rm s}^{\\rm state} &amp;\\sim {\\rm normal}(A^{\\rm region}_{n[s]} + B^{\\rm repvote} \\cdot {\\rm RepVote}_{\\rm s}, \\sigma^{\\rm state}) \\textrm{ for s = 1,...,50}\\\\ A_{\\rm a}^{\\rm age} &amp; \\sim {\\rm normal}(0,\\sigma^{\\rm age}) \\textrm{ for a = 1,...,6}\\\\ A_{\\rm r}^{\\rm ethnicity} &amp; \\sim {\\rm normal}(0,\\sigma^{\\rm ethnicity}) \\textrm{ for r = 1,...,4}\\\\ A_{\\rm e}^{\\rm education} &amp; \\sim {\\rm normal}(0,\\sigma^{\\rm education}) \\textrm{ for e = 1,...,5}\\\\ A_{\\rm n}^{\\rm region} &amp; \\sim {\\rm normal}(0,\\sigma^{\\rm region}) \\textrm{ for a = 1,...,4}\\\\ \\end{align*} \\] Note that our model is fundamentally different from the two-step approach used by Tausanovitch and Warshaw (2013). By first estimating the ideal point of each individual and then using MRP, their method is not propagating the uncertainty about the estimated ideal points into the final national or subnational estimates. Considering one of the essential advantages of Bayesian inference is to properly quantify uncertainty, we include the multilevel stage of the MRP within the ideal point model model. Thus, in our model the multilevel regression serves as a prior for \\(\\alpha_j\\). In this example we have included the same predictors introduced in first chapter, excluding the interaction terms for simplicity. As we already introduced in the previous section, identification can be achieved by transforming the ability, difficulty, and discrimination parameters by \\(\\alpha_j^{\\rm adj} = \\frac{\\alpha_j - \\bar{\\alpha}}{s_{\\alpha}}\\), \\(\\beta_k^{\\rm adj} = \\frac{\\beta_k - \\bar{\\alpha}}{s_{\\alpha}}\\), \\(\\gamma_k^{\\rm adj} = \\gamma_k s_{\\alpha}\\). We also restricted \\(\\gamma_k &gt; 0\\), which in turn requires precoding all the questions. The first question was reversed in order for all the outcomes to reflect a supporting perspective on restricting abortion rights. Therefore, a high ability \\(\\alpha_j^{\\rm adj}\\) will represent a strong opposition to abortion. 4.2.1 Bayesian estimation In this initial experiment we analyzed the six abortion responses for a random sample of 5,000 CCES participants. The Stan code we used is shown below, and was fitted using 5 chains with 2,000 iterations (500 warmup). # We skip reading the data, as the process is exactly the same as in chapter 1 except for reading six questions # in the CCES instead of only one. See Github repo for the entire code. # Melt df for Stan df_melted &lt;- df %&gt;% select(starts_with(&quot;abortion&quot;), state, ethnicity, age, educ, male, region, subject) %&gt;% melt(id.vars = c(&quot;state&quot;, &quot;age&quot;, &quot;ethnicity&quot;, &quot;educ&quot;, &quot;male&quot;, &quot;region&quot;, &quot;subject&quot;)) # Prepare data for Stan data &lt;- list(J = length(unique(df_melted$subject)), K = length(unique(df_melted$variable)), N = nrow(df_melted), S = nrow(statelevel_predictors), P = nrow(postrat_df), participant = as.numeric(df_melted$subject), question = as.numeric(df_melted$variable), state = as.numeric(df_melted$state), age = as.numeric(df_melted$age), ethnicity = as.numeric(df_melted$ethnicity), educ = as.numeric(df_melted$educ), male = as.numeric(df_melted$male), region = as.numeric(statelevel_predictors$region), repvote = statelevel_predictors$repvote, postrat_state = as.numeric(postrat_df$state), postrat_age = as.numeric(postrat_df$age), postrat_ethnicity = as.numeric(postrat_df$ethnicity), postrat_educ = as.numeric(postrat_df$educ), postrat_male = postrat_df$male, y = df_melted$value) # Only train if train = TRUE; if not, load from fit_idealpoint.rds train = FALSE if(train){ fit_id &lt;- stan_model(&quot;idealpoint.stan&quot;) fit &lt;- sampling(fit_id, data = data, iter = 2000, warmup = 1000, chains = 5, control = list(adapt_delta = 0.99, max_treedepth = 12), refresh = 25) saveRDS(fit, file = &quot;fit_idealpoint.rds&quot;) } else { fit &lt;- readRDS(&quot;fit_idealpoint.rds&quot;) } # Extract draws as dataframe df_fit &lt;- rstan::extract(fit) 4.2.2 Initial Results We can visualize the posterior distribution for the estimated \\(\\alpha_j^{adj}\\) of the first five participants: Conversely, we can visualize the distribution of \\(\\alpha_j^{adj}\\) for a random subset of the posterior draws: As a first check that the ideal points \\(\\alpha_j^{adj}\\) estimated by the model are capturing a meaningful latent variable, we correlate them with the reported ideology in the CCES by each participant \\(j\\). This results in a correlation of 0.53. We can plot the distribution for a one single draw of \\(\\alpha_j^{adj}\\), but selecting only CCES respondents from California and Tennessee, which provides an approximation of the between-state and within-state variations. Not surprisingly, individuals from Tennessee tend to have higher ideal points. Lastly, we can also visualize the probability of supporting each statement for the potential values of \\(\\alpha_j^{adj}\\). 4.3 The Abortion Opposition Index for US States Assuming our poststratification table has \\(T\\) cells that reflect different geographic-demographic combinations, the ideal point model allows to estimate the expected ability \\(\\mu_{\\alpha_t}\\) for each of these combinations. Before poststratification, we need to transform this \\(\\mu_{\\alpha_t}\\) into \\(\\mu_{\\alpha^{adj}_t}\\) by considering that \\(\\mu_{\\alpha^{adj}_t} = \\frac{\\mu_{\\alpha_t} - \\bar{\\alpha}}{s_{\\alpha}}\\). In order to do this we: Draw with replacement \\(L\\) individuals from the poststratification table (weighting by \\(N\\), the number of people in each cell). Calculate \\(\\mu_{\\alpha_l}\\) for each subject \\(l\\), and then add some random noise centered at zero and with standard deviation \\(\\sigma_\\alpha\\) (which was estimated in the model). This simulates the \\(\\alpha_l\\) for a random sample of \\(L\\) subjects that come from the population defined by the poststratification table. Given \\(\\alpha_l\\), calculate \\(\\bar{\\alpha}_l\\) and \\(s_{\\alpha_l}\\). These values correspond to the estimated average and standard deviation for the abilities in the population defined by the poststratification table. Calculate \\(\\mu_{\\alpha^{adj}_t} = \\frac{\\mu_{\\alpha_t} - \\bar{\\alpha}_l}{s_{\\alpha_l}}\\) This process is repeated for each draw of the posterior distribution. If we have \\(D\\) draws and \\(T\\) poststratification cells, \\(\\mu_{\\alpha^{adj}_t}\\) will be a \\(D \\times T\\) matrix. # Calculating mu_alpha_adj ndraws &lt;- nrow(df_fit$alpha_pred_raw) L &lt;- 10000 mu_alpha_adj &lt;- matrix(NA, nrow = ndraws, ncol = 12000) for(d in 1:ndraws){ mu_alpha &lt;- df_fit$mu_alpha[d] + df_fit$alpha_pred_raw[d,] sample_alphas_pop &lt;- sample(mu_alpha, size = L, prob = postrat_df$n/sum(postrat_df$n), replace = TRUE) sample_alphas_pop &lt;- sample_alphas_pop + rnorm(L, 0, df_fit$sigma_alpha[d]) mean_alpha &lt;- mean(sample_alphas_pop) sd_alpha &lt;- sd(sample_alphas_pop) mu_alpha_adj[d,] &lt;- (mu_alpha - mean_alpha) / sd_alpha } \\(\\mu_{\\alpha^{adj}_t}\\) can be poststratified as usual in order to obtain state-level ideal points that reflect what we may refer as the Abortion Opposition Index. It is important to clarify that these final sub-national estimates are relative to the national level (which is, as defined in the model, equal to zero). ### Poststratification national_level &lt;- mu_alpha_adj %*% postrat_df$n / sum(postrat_df$n) df_state_idealpoint &lt;- data.frame(state = rep(NA, length(levels(df$state))), idealpoint_mean = NA, idealpoint_sd = NA) i = 1 for(s in levels(df$state)){ state_estimates &lt;- (mu_alpha_adj[, which(postrat_df$state==s)] %*% postrat_df$n[which(postrat_df$state==s)]/ sum(postrat_df$n[which(postrat_df$state==s)]) ) df_state_idealpoint$state[i] &lt;- s df_state_idealpoint$idealpoint_mean[i] &lt;- mean(state_estimates) df_state_idealpoint$idealpoint_sd[i] &lt;- sd(state_estimates) i = i + 1 } The correlation between these state-level estimates and Republican voteshare in the 2016 election is 0.99. 4.3.1 Comparison with simple sum A simpler approach for obtaining estimates about the latent abortion opposition is to consider the sum of the six questions for each respondent as the outcome, fitting a multilevel linear regression and poststratifying as usual. df$abortion_score &lt;- rowSums(select(df, abortion1, abortion2, abortion3, abortion4, abortion5, abortion6)) train = FALSE if(train){ fit_sum &lt;- stan_glmer(abortion_score ~ (1 | state) + (1 | ethnicity) + (1 | age) + (1 | educ) + male + repvote + (1 | region), data = df, prior = normal(0, 1, autoscale = TRUE), prior_covariance = decov(scale = 0.50), adapt_delta = 0.99, seed = 1010) saveRDS(fit_sum, file = &quot;fit_sum.rds&quot;) } else { fit_sum &lt;- readRDS(file = &quot;fit_sum.rds&quot;) } P &lt;- posterior_epred(fit_sum, newdata = left_join(postrat_df, statelevel_predictors)) df_state_sum &lt;- data.frame(state = levels(postrat_df$state), sum_mean = NA, sum_sd = NA, sum_mean_relative = NA) national_level &lt;- P %*% postrat_df$n / sum(postrat_df$n) for(i in 1:length(levels(postrat_df$state))) { filtering_condition &lt;- which(postrat_df$state == as.character(df_state_sum$state[i])) P_filtered &lt;- P[ ,filtering_condition] k_filtered &lt;- postrat_df[filtering_condition, ]$n poststrat_prob_state &lt;- P_filtered %*% k_filtered / sum(k_filtered) df_state_sum$sum_mean[i] &lt;- mean(poststrat_prob_state) df_state_sum$sum_sd[i] &lt;- sd(poststrat_prob_state) } These results are very similar to what we obtained with the ideal-point model. In fact, the state-level point estimates produced by the two methods have a correlation of 0.9985. Still, the ideal point model results in more precise results, with an average absolute \\(t\\) of 3.06 that is higher than the 1.58 produced by naive sum of question outcomes. 4.3.2 Fake-data simulation We expect the ideal point model to be similar to the naive sum approach when all the questions are equally relevant to the latent variable. Conversely, when some of the questions are more relevant than others we expect the ideal point model will perform better both in terms of reduced error and tighter standard error. To demostrate this we use fake data simulation. We draw 2,500 individuals according to the weights provided by the poststratification table, calculate their true ideal point based on pre-specified values for the multilevel predictors, and then define six questions. In one case we will use six questions which are approximately equally relevant (\\(\\mu^{\\gamma} = 2\\), \\(\\sigma^{\\gamma} = 0.2\\)), while in the other we will use six questions with very different discrimination parameters (\\(\\mu^{\\gamma} = 2\\), \\(\\sigma^{\\gamma} = 0.8\\)). 4.3.2.1 Questions with similar discrimination parameters When we consider six questions with little variation across their discrimination parameters, the results for the ideal point MRP and the sum MRP are very similar both in terms of MAE and mean SE. The ideal point MRP estimates and the true values are in the same scale, but the naive sum MRP are not. In order to compare them we standarize the subnational estimates that result from the three methods. 4.3.2.2 Questions with different discrimination values When the questions have very different \\(\\gamma_k\\), the advantage of ideal point MRP is more remarkable, both in terms of lower mean SE and smaller Mean Absolute Error. Lastly, we see that the ideal point MRP has been able to recover the true \\(\\gamma_k\\) and \\(\\beta_k\\) for each question. true_gamma estimated_gamma true_beta estimated_beta 2.3 2.41 0.0 0.02 3.0 2.89 1.0 0.98 1.3 1.33 -1.0 -0.89 0.3 0.26 0.5 0.33 2.8 2.74 -0.5 -0.46 1.7 1.60 0.0 -0.01 4.4 Estimating Support for Individual Questions Based on the estimated \\(\\mu^{\\alpha}\\), \\(A_{\\rm s[j]}^{\\rm state}\\), \\(A_{\\rm a[j]}^{\\rm age}\\), \\(A_{\\rm r[j]}^{\\rm ethnicity}\\), \\(A_{\\rm e[j]}^{\\rm education}\\), and \\(B^{\\rm male}\\) we can estimate \\(\\mu_{\\alpha_j}\\), the average ability for each cell \\(j\\) in the poststratification table. This was the quantity that previously we standardized into \\(\\mu_{\\alpha^{adj}_j}\\) and used in the poststratification step, obtaining state-level estimates for the ideal points. These average ability estimates can instead be transformed with \\(logit^{-1}(\\gamma_{k}^{adj}(\\mu_{\\alpha_j}^{adj} - \\beta_{k}^{adj}))\\). The result is an estimate of the probability of supporting question \\(k\\) for the average ability corresponding to each poststratification cell. 4.4.1 Mind the (Jensens) gap \\(\\mu_{\\alpha^{adj}_j}\\) reflects the (standardized) average ideal point position for each poststratification cell, which can be transformed into the probability of the average person in this cell \\(j\\) supporting a given statement \\(k\\). However, this quantity is not particularly interesting for us. What we really need to estimate is the average probability that the individuals in cell \\(j\\) support statement \\(k\\). In a simplified example, what we have estimated is the probability that the average Texan supports a given statement. However, our goal is to obtain the average support of that statement for the people in Texas. For this, we need to consider that, for each poststratification cell \\(j\\), \\(\\alpha_j \\sim N(\\mu_{\\alpha_j} \\sigma_\\alpha)\\). Naively using \\(\\mu_{\\alpha_j}\\) or its standardized version, as we have done in the previous subsection, results in estimates that are too extreme. As a result of Jensens inequality and the properties of the logistic function, if we use a nonlinear transformation \\(f(x) = logit^{-1}(g(x - b))\\) (where \\(g&gt;0\\)) on a random variable \\(X\\) we will obtain that \\(f(E[X]) \\leq E[f(X)]\\) when \\(f(x)\\) is convex (i.e. when \\(X - b &lt; 0\\)) and \\(f(E[x]) \\geq E[f(x)]\\) when it is concave (i.e. when \\(X - b &gt; 0\\)). We can show this by simulating multiple draws from \\(X \\sim N(0, \\sigma)\\) and transforming them with \\(f(x) = logit^{-1}(x)\\) (i.e. in our example, \\(b = 0\\) and \\(g = 1\\)): In essence, using \\(\\mu_{\\alpha_j}\\) or its standardized version will result in more extreme estimates due to the nonlinearity in the transformation. However, obtaining reliable estimates of the probability of support of question \\(k\\) for each poststratification cell \\(j\\) is still possible: Draw with replacement \\(L\\) individuals from the poststratification table (weighting by \\(N\\), the number of people in each cell). Calculate \\(\\mu_{\\alpha_l}\\) for each subject \\(l\\), and then add some random noise centered at zero and with standard deviation \\(\\sigma_\\alpha\\) (which was estimated in the model). This simulates the \\(\\alpha_l\\) for a random sample of \\(L\\) subjects that come from the population defined by the poststratification table. Given \\(\\alpha_l\\), calculate \\(\\bar{\\alpha}_l\\) and \\(s_{\\alpha_l}\\). These values correspond to the estimated average and standard deviation for the abilities in the population defined by the poststratification table. For each poststratification cell \\(t\\): Simulate \\(s\\) draws from the distribution of alphas \\(\\alpha_s \\sim \\text{normal}(\\mu_{\\alpha_t}, \\sigma_\\alpha)\\). These \\(s\\) draws correspond to individuals with the demographic-geographic factors defined in cell \\(t\\). Standardize \\(\\alpha_s^{adj} = \\frac{\\alpha_s - \\bar{\\alpha}_l}{s_{\\alpha_l}}\\) Considering \\(\\alpha_s^{adj}\\) is a vector with \\(s\\) elements, obtain \\(P(y_{k,t} = 1) = \\text{Mean}(logit^{-1}(\\gamma_k^{adj}\\times(\\alpha_s^{adj} - \\beta_k^{adj})))\\) \\(P(y_{k,t} = 1)\\) represents the average support for question \\(k\\) among individuals in cell \\(t\\). To propagate the uncertainty about the parameters in the model, these steps must be repeated once for every posterior draw \\(d\\), obtaining a \\(D \\times T\\) matrix that can be poststratified as usual. 4.4.2 Results from Standard and Ideal Point MRP We compare the individual-question estimates for the ideal point model and the standard model. As expected, the results from both methods are similar, although there are also some differences. 4.4.2.1 Question 6 Make abortions illegal in all circumstances The following code implements the algorithm described above that results in the \\(D \\times T\\) matrix \\(P(y_{k,t} = 1)\\). Instead of considering the \\(D\\) posterior draws, we only use 25 for computational efficiency. This \\(P(y_{k,t} = 1)\\) matrix is then poststratified and, ultimately, we obtain the national and state-level estimates. question_number &lt;- 6 df_fit &lt;- rstan::extract(fit) ndraws &lt;- 25 # sample of draws to reduce computation time nsims &lt;- 50 L &lt;- 1000 sample_draws &lt;- sample(nrow(df_fit$alpha_pred_raw), size = ndraws) question_pred &lt;- matrix(NA, ncol = 12000, nrow = ndraws) for(d in 1:ndraws){ mu_alpha &lt;- df_fit$mu_alpha[sample_draws[d]] + df_fit$alpha_pred_raw[sample_draws[d],] sample_alphas_pop &lt;- sample(mu_alpha, size = L, prob = postrat_df$n/sum(postrat_df$n), replace = TRUE) sample_alphas_pop &lt;- sample_alphas_pop + rnorm(L, 0, df_fit$sigma_alpha[sample_draws[d]]) mean_alpha &lt;- mean(sample_alphas_pop) sd_alpha &lt;- sd(sample_alphas_pop) for(t in 1:12000){ alpha_pred &lt;- mu_alpha[t] + rnorm(nsims, 0, df_fit$sigma_alpha[sample_draws[d]]) alpha_pred &lt;- (alpha_pred - mean_alpha)/sd_alpha question_pred[d,t] &lt;- mean(plogis(df_fit$gamma_adj[sample_draws[d], question_number]*(alpha_pred - df_fit$beta_adj[sample_draws[d], question_number]))) } } national_level_idealpoint &lt;- question_pred %*% postrat_df_numeric$n / sum(postrat_df_numeric$n) df_state_idealpoint &lt;- data.frame(state = 1:max(postrat_df_numeric$state), idealpoint_mean = NA, idealpoint_sd = NA) for(s in 1:max(postrat_df_numeric$state)){ state_estimates &lt;- question_pred[, which(postrat_df_numeric$state==s)] %*% postrat_df$n[which(postrat_df_numeric$state==s)]/ sum(postrat_df_numeric$n[which(postrat_df_numeric$state==s)]) df_state_idealpoint$state[s] &lt;- s df_state_idealpoint$idealpoint_mean[s] &lt;- mean(state_estimates) df_state_idealpoint$idealpoint_sd[s] &lt;- sd(state_estimates) } df_state_idealpoint$state &lt;- statelevel_predictors$state The results are plotted along the full-CCES disaggregated estimates and the estimates obtained with standard MRP. The mean SE for the state-level ideal point MRP estimates is 1.16%, while the standard MRP produces an average SE of 2.24%. Measuring the error of the point estimates is trickier, as there is no clear ground-truth in this case. The closest we can consider are the estimates from the full-sample CCES. If we compare the state-level ideal point MRP estimates to the results from full-sample CCES, we obtain a MAE of 2.09%, while if the comparison is made with the standard MRP we obtain a MAE of 2.17%. 4.4.2.2 Question 5 Prohibit the expenditure of funds authorized or appropriated by federal law for any abortion Ideal point MRP mean SE: 2.44%, Standard MRP mean SE: 2.27%. Ideal point MRP MAE with respect to results from full-sample CCES:3.26% Standard MRP MAE with respect to results from full-sample CCES: 3.68%. 4.4.2.3 Question 4 Allow employers to decline coverage of abortions in insurance plans Ideal point MRP mean SE: 2.28%, Standard MRP mean SE: 2.61%. Ideal point MRP MAE with respect to results from full-sample CCES:3.19% Standard MRP MAE with respect to results from full-sample CCES: 3.13%. 4.4.2.4 Question 3 Ban abortions after the 20th week of pregnancy Ideal point MRP mean SE: 2.11%, Standard MRP mean SE: 2.12%. Ideal point MRP MAE with respect to results from full-sample CCES:2.37% Standard MRP MAE with respect to results from full-sample CCES: 2.14%. 4.4.2.5 Question 2 Permit abortion ONLY in case of rape, incest or when the womans life is in danger Ideal point MRP mean SE: 2.07%, Standard MRP mean SE: 2.14%. Ideal point MRP MAE with respect to results from full-sample CCES:3.28% Standard MRP MAE with respect to results from full-sample CCES: 4.41%. 4.4.2.6 Question 1 Always allow a woman to obtain an abortion as a matter of choice (reversed) Ideal point MRP mean SE: 2.17%, Standard MRP mean SE: 2.31%. Ideal point MRP MAE with respect to results from full-sample CCES:3.15% Standard MRP MAE with respect to results from full-sample CCES: 3.43%. 4.4.3 Comparing ideal point and standard MRP using fake-data simulation Although with some exceptions, the ideal point MRP estimates seem to have lower standard errors and tend to be closer to the full-sample CCES. To compare these two methods in a more controlled setting we use fake data simulation. The DGP assumess each of the 9 questions reflects a (unique) true ideal point with varying difficulty and discrimination. The ideal point is in turn determined by a set of demographic-geographic predictors and some normally-distributed random error. We simulate a population of 10 million individuals based on the weights in the poststratification table, and then obtain a sample of 3,000 participants that is then used for the ideal point MRP and standard MRP state-level estimation for each question. These state-level estimates are evaluated in terms of their average standard error and mean absolute error with respect to the true support in the population. Below the plot the estimates for three of the simulated questions. Instead of focusing solely on the results from the 3,000 person sample, we will take samples between \\(N = 1000\\) and \\(N = 5000\\) from the simulated population and compare the results of the ideal point MRP and standard MRP on each of the 9 questions. With very few exceptions, the estimates from the ideal point MRP result in a lower MAE and mean SE for all the question and for all the different sample sizes. To further emphasize this point, we plot the average MAE and mean SE across questions as a function of method and sample size. 4.4.4 A note of caution We have shown that the ideal point MRP tends to perform better than standard MRP using both CCES data and fake data. This improvement is due to the model being able to capture useful information from other questions and, thus, provide better estimates for the question of interest. However, ideal point MRP could be detrimental relative to standard MRP if the questions were not relevant with respect to the same latent construct. Our CCES data used six questions that, although obviously slightly different in terms of the position they intend to measure, all were closely related to a general attitude towards abortion. Conversely, including unrelated questions, such as support for certain foreign policy, could negatively influence our estimates. Therefore, we would restrict the use of ideal point MRP to situations where there is a clear convergence between the survey items. 4.5 Concluding remarks This Chapter has introduced ideal point MRP and explored its use in two different applications: Obtaining sub-national (or sub-group) estimates of latent attitudes using multiple survey items: Based on a set of related questions about abortion, we used ideal point MRP to produce state-level estimates of an Abortion Opposition Index. This method easily handles spareness (i.e. when each respondent has not answered each question), and even when this is not an issue it can provide an advantage over naively summing the dichotomous responses when the questions have different discriminatory power  which is, in practice, always the case. Improving estimates for an individual question: Ideal point MRP can also present an advantage over standard MRP when our interest is focused in one single question as long as the surveys includes other related items. In this situation, standard MRP only considers the question of interest, ignoring the responses to the other relevant questions. Conversely, the ideal point model is able to consider the relevant information contained in the other related items, and thus provide better estimates with smaller uncertainty. This advantage can be especially consequential in surveys with a small sample size. 4.6 Appendix // // Ideal Point Multilevel Modeling and Postratification // data { int&lt;lower=1&gt; J; //Participants int&lt;lower=1&gt; K; //Questions int&lt;lower=1&gt; N; //no. of observations int&lt;lower=1&gt; S; //no. of states int&lt;lower=1&gt; P; //no. of states int&lt;lower=1, upper=J&gt; participant[N]; // Participant for observation n int&lt;lower=1, upper=K&gt; question[N]; // Question for observation n int&lt;lower=1, upper=S&gt; state[N]; // State for observation n int&lt;lower=1, upper=6&gt; age[N]; // Age for observation n int&lt;lower=1, upper=4&gt; ethnicity[N]; // Ethnicity for observation n int&lt;lower=1, upper=5&gt; educ[N]; // Education for observation n real&lt;lower=-0.5, upper=0.5&gt; male[N]; // Gender for observation n int&lt;lower=0, upper=4&gt; region[S]; // Region for state s real repvote[S]; // Republican voteshare for state s int&lt;lower=0, upper=1&gt; y[N]; // Support for observation n int&lt;lower=1, upper=S&gt; postrat_state[P]; int&lt;lower=1, upper=6&gt; postrat_age[P]; int&lt;lower=1, upper=4&gt; postrat_ethnicity[P]; int&lt;lower=1, upper=5&gt; postrat_educ[P]; real&lt;lower=-0.5, upper=0.5&gt; postrat_male[P]; } parameters { vector[S] alpha_state_raw; vector[6] alpha_age_raw; vector[5] alpha_educ_raw; vector[4] alpha_ethnicity_raw; vector[4] alpha_region_raw; real beta_male; real beta_repvote; real&lt;lower=0&gt; sigma_state; real&lt;lower=0&gt; sigma_age; real&lt;lower=0&gt; sigma_ethnicity; real&lt;lower=0&gt; sigma_educ; real&lt;lower=0&gt; sigma_region; real mu_alpha; real&lt;lower=0&gt; sigma_alpha; real mu_beta; real&lt;lower=0&gt; sigma_beta; real&lt;lower=0&gt; mu_gamma; real&lt;lower=0&gt; sigma_gamma; vector[K] beta_raw; vector[J] alpha_raw; vector&lt;lower=0&gt;[K] gamma_raw; } transformed parameters{ vector[6] alpha_age = 0 + sigma_age*alpha_age_raw; vector[5] alpha_educ = 0 + sigma_educ*alpha_educ_raw; vector[4] alpha_ethnicity = 0 + sigma_ethnicity*alpha_ethnicity_raw; vector[4] alpha_region = 0 + sigma_region*alpha_region_raw; vector[K] beta = mu_beta + sigma_beta*beta_raw; vector[K] gamma = mu_gamma + sigma_gamma*gamma_raw; vector[S] alpha_state; vector[J] alpha; real alpha_mean; real alpha_sd; vector[J] alpha_adj; vector[K] beta_adj; vector&lt;lower=0&gt;[K] gamma_adj; for(s in 1:S) alpha_state[s] = alpha_region[region[s]] + beta_repvote*repvote[s] + sigma_state*alpha_state_raw[s]; for (j in 1:J) alpha[j] = mu_alpha + alpha_state[state[j]] + alpha_age[age[j]] + alpha_ethnicity[ethnicity[j]] + alpha_educ[educ[j]] + beta_male*male[j] + sigma_alpha*alpha_raw[j]; alpha_mean = mean(alpha); alpha_sd = sd(alpha); alpha_adj = (alpha - alpha_mean)/alpha_sd; beta_adj = (beta - alpha_mean)/alpha_sd; gamma_adj = gamma*alpha_sd; } model { //priors on predictors sigma_state ~ exponential(0.5); // prior for sigma_state sigma_age ~ exponential(0.5); // prior for sigma_age sigma_ethnicity ~ exponential(0.5); // prior for sigma_ethnicity sigma_educ ~ exponential(0.5); // prior for sigma_educ sigma_region ~ exponential(0.5); // prior for sigma_educ beta_male ~ normal(0, 2); // prior for beta_male beta_repvote ~ normal(0, 2); // prior for beta_repvote //priors on parameters mu_beta ~ normal(0, 2); // prior for mu_beta sigma_beta ~ exponential(1); // prior for sigma_beta mu_gamma ~ normal(0, 2); // prior for mu_gamma sigma_gamma ~ exponential(1); // prior for sigma_gamma alpha_state_raw ~ std_normal(); // implies alpha_state ~ normal(alpha_region, sigma_state) alpha_age_raw ~ std_normal(); // implies alpha_age ~ normal(0, sigma_age) alpha_ethnicity_raw ~ std_normal(); // implies alpha_ethnicity ~ normal(0, sigma_ethnicity) alpha_educ_raw ~ std_normal(); // implies alpha_educ ~ normal(0, sigma_educ) alpha_region_raw ~ std_normal(); // implies alpha_region ~ normal(0, sigma_region) gamma_raw ~ std_normal(); // implies beta ~ normal(mu_beta, sigma_beta) beta_raw ~ std_normal(); // implies beta ~ normal(mu_beta, sigma_beta) alpha_raw ~ std_normal(); // implies alpha ~ normal(mu_alpha + alpha_state + alpha_age + ..., sigma_alpha) for (n in 1:N) y[n] ~ bernoulli_logit(gamma_adj[question[n]] * (alpha_adj[participant[n]] - beta_adj[question[n]])); } generated quantities{ vector[P] alpha_pred_raw; vector[P] alpha_pred; for (p in 1:P) alpha_pred_raw[p] = alpha_state[postrat_state[p]] + alpha_age[postrat_age[p]] + alpha_ethnicity[postrat_ethnicity[p]] + alpha_educ[postrat_educ[p]] + beta_male*postrat_male[p]; } References "],["references.html", "References", " References "]]
